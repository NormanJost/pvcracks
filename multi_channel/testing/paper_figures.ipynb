{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90157b40",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf09b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import functions\n",
    "from tutorials.unet_model import construct_unet\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a38324",
   "metadata": {},
   "source": [
    "---\n",
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4dc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root, channeled=True):\n",
    "    if not channeled:\n",
    "        transformers = functions.Compose(\n",
    "            [functions.FixResize(256), functions.ToTensor(), functions.Normalize()]\n",
    "        )\n",
    "    else:\n",
    "        # Channeled dataset\n",
    "        transformers = functions.Compose(\n",
    "            [\n",
    "                functions.ChanneledFixResize(256),\n",
    "                functions.ToTensor(),\n",
    "                functions.Normalize(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    val_dataset = functions.SolarDataset(\n",
    "        root, image_folder=\"img/val\", mask_folder=\"ann/val\", transforms=transformers\n",
    "    )\n",
    "\n",
    "    return val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_device_and_model(weight_path, category_mapping):\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "    unet = construct_unet(len(category_mapping))\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "\n",
    "    checkpoint = torch.load(weight_path, map_location=device)\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint.items():\n",
    "        name = \"module.\" + k\n",
    "        new_state_dict[name] = v\n",
    "    unet.load_state_dict(new_state_dict)\n",
    "\n",
    "    model = unet.module.to(device)\n",
    "\n",
    "    return device, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddcc25",
   "metadata": {},
   "source": [
    "---\n",
    "# Plotting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15307ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_row_inference_and_show(idx, root, weight_path, category_mapping, threshold=0.5):\n",
    "    val_dataset = load_dataset(root)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    device, model = load_device_and_model(weight_path, category_mapping)\n",
    "\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = val_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # Get the raw image for display (assuming __getraw__ returns a PIL image)\n",
    "    raw_img, _ = val_loader.dataset.__getraw__(idx)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 4, H, W]\n",
    "    probs = torch.sigmoid(logits)  # shape: [1, 4, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [4, H, W]\n",
    "\n",
    "    # Ground truth is assumed to be already a 4-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [4, H, W]\n",
    "\n",
    "    # --- Visualization ---\n",
    "    # Create a grid with 3 rows and 4 columns:\n",
    "    #   Row 0: Raw image (displayed only once in the first column)\n",
    "    #   Row 1: Ground truth masks for each class\n",
    "    #   Row 2: Predicted masks for each class\n",
    "    n_classes = len(category_mapping)\n",
    "    class_names = [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "\n",
    "    fig, axs = plt.subplots(3, n_classes, figsize=(4 * n_classes, 12))\n",
    "\n",
    "    # Row 0: Display raw image in first subplot; hide other subplots in this row.\n",
    "    axs[0, 0].imshow(raw_img.convert(\"L\"), cmap=\"viridis\")\n",
    "    axs[0, 0].set_title(\"Raw Image\")\n",
    "    axs[0, 0].axis(\"off\")\n",
    "    for j in range(1, n_classes):\n",
    "        axs[0, j].axis(\"off\")\n",
    "\n",
    "    # Row 1: Ground truth for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[1, j].imshow(gt_mask[j], cmap=\"viridis\")\n",
    "        axs[1, j].set_title(f\"GT: {class_names[j]}\")\n",
    "        axs[1, j].axis(\"off\")\n",
    "\n",
    "    # Row 2: Predictions for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[2, j].imshow(pred_mask[j], cmap=\"viridis\")\n",
    "        axs[2, j].set_title(f\"Pred: {class_names[j]}\")\n",
    "        axs[2, j].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(\"New Model Prediction\", fontsize=16)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_row_inference_and_show(idx, root, weight_path, category_mapping, threshold=0.5):\n",
    "    val_dataset = load_dataset(root, channeled=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    device, model = load_device_and_model(weight_path, category_mapping)\n",
    "\n",
    "    img, mask = val_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    raw_img, _ = val_loader.dataset.__getraw__(idx)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    logits = (\n",
    "        model(img.unsqueeze(0)).detach().cpu().numpy().squeeze(0)\n",
    "    ) \n",
    "    pred_mask = np.argmax(logits, axis=0)\n",
    "\n",
    "    gt_mask = mask.cpu().numpy() \n",
    "\n",
    "    # --- Visualization ---\n",
    "    n_classes = len(category_mapping)\n",
    "\n",
    "    class_names = [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "    cmap = mpl.colormaps[\"viridis\"].resampled(n_classes)  # define the colormap\n",
    "    cmaplist = [cmap(i) for i in range(n_classes)]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12, 6))\n",
    "\n",
    "    im = ax[0].imshow(raw_img.convert(\"L\"), cmap=\"viridis\", interpolation=\"None\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Raw Image\")\n",
    "\n",
    "    im = ax[1].imshow(gt_mask, cmap=\"viridis\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "    ax[2].imshow(pred_mask, cmap=\"viridis\", interpolation=\"None\")\n",
    "    handles, labels = ax[2].get_legend_handles_labels()\n",
    "    for c, class_name in zip(\n",
    "        cmaplist, class_names\n",
    "    ):\n",
    "        patch = mpatches.Patch(color=c, label=class_name, ec=\"k\")\n",
    "        handles.append(patch)\n",
    "    ax[2].legend(handles=handles, fontsize=\"x-small\")\n",
    "    ax[2].axis(\"off\")\n",
    "    ax[2].set_title(\"New Model Prediction\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_model_outputs(idx, root, weight_path, category_mapping):\n",
    "    val_dataset = load_dataset(root, channeled=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    device, model = load_device_and_model(weight_path, category_mapping)\n",
    "\n",
    "    img, mask = val_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "    \n",
    "    test_res = model(img.unsqueeze(0)).detach().cpu().numpy().squeeze()  # .argmax(axis = 0)\n",
    "    test_res = np.argmax(test_res, axis=0)\n",
    "\n",
    "    sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "    test_res_chan = model(img.unsqueeze(0)).detach().cpu().numpy().squeeze()\n",
    "    test_res_act = sigmoid(test_res_chan)\n",
    "    \n",
    "    yslice = 130\n",
    "    # yslice= 180\n",
    "    xmax = 60\n",
    "    ymax = 256\n",
    "\n",
    "    sliced = test_res_act[:, yslice, :]\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 6), sharex=True)\n",
    "\n",
    "    for i in range(sliced.shape[0]):\n",
    "        ax[0].fill_between(\n",
    "            np.arange(0, 256, 1), sliced[i], alpha=0.3, label=category_mapping[i]\n",
    "        )\n",
    "    ax[0].legend()\n",
    "    ax[0].set_ylabel(f\"Activated model outputs at y = {yslice}\", fontsize=\"xx-large\")\n",
    "\n",
    "    ax[1].imshow(test_res_chan.sum(axis=0), cmap=\"magma\")\n",
    "    ax[1].set_aspect(\"auto\")\n",
    "    ax[1].axhline(yslice, ls=\"--\", c=\"black\", alpha=0.9, label=f\"y = {yslice}\", linewidth=3)\n",
    "    ax[1].legend()\n",
    "    ax[1].set_title(\"Raw model outputs\", fontsize=\"xx-large\")\n",
    "    ax[1].set_ylabel(\"y pixel position\", fontsize=\"xx-large\")\n",
    "    fig.supxlabel(\"x pixel position\", fontsize=\"xx-large\")\n",
    "    # fig.suptitle(val_loader.dataset. __getname__(cr_idx))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ax[0].legend(fontsize='xx-large')  # or a number, e.g., fontsize=14\n",
    "    ax[1].legend(fontsize='xx-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665d1f6",
   "metadata": {},
   "source": [
    "---\n",
    "# Running plot-creating code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06778d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"dark\", 1: \"busbar\", 2: \"crack\", 3: \"non-cell\"}\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty/\"\n",
    ")\n",
    "# weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty_Optimized/model.pt\"\n",
    "# weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty_Optimized/model_epoch39_paramaters-wandb.pt\"\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty/checkpoints/Channeled_Combined_CWRU_LBNL_ASU_No_Empty10/epoch_19/model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_row_inference_and_show(7, root, weight_path, category_mapping)\n",
    "# for i in range(0, 101):\n",
    "#     print(i)\n",
    "#     two_row_inference_and_show(i, root, weight_path, category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd443275",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 101):\n",
    "    print(i)\n",
    "    two_row_inference_and_show(i, root, weight_path, category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81707920",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423320eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"non-cell\"}\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/\"\n",
    ")\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/checkpoints/Combined_CWRU_SE_Dupont_and_LBNL_Mono2/epoch_30/Combined_CWRU_SE_Dupont_and_LBNL_Mono.pt\"\n",
    "\n",
    "one_row_inference_and_show(21, root, weight_path, category_mapping)\n",
    "\n",
    "# for i in range(0, 50):\n",
    "#     one_row_inference_and_show(i, root, weight_path, category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8845f20",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"non-cell\"}\n",
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_Combined_CWRU_LBNL_ASU/\"\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_Combined_CWRU_LBNL_ASU/checkpoints/Fresh_Combined_CWRU_LBNL_ASU1/epoch_30/model.pt\"\n",
    "\n",
    "\n",
    "bu_name = \"bu_2_EL_18.09.2023-15-27-31_unknownID_ASU Minisample_SHJ1_91.npy\"\n",
    "cr_name = \"cr_2_EL_18.09.2023-15-27-31_unknownID_ASU Minisample_SHJ1_91.npy\"\n",
    "ann_dir = root + \"ann/val/\"\n",
    "val_dataset = load_dataset(root, channeled=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "cr_idx = np.ravel(\n",
    "    np.where(val_loader.dataset.mask_list == os.path.join(ann_dir, cr_name))\n",
    ")[0]\n",
    "bu_idx = np.ravel(\n",
    "    np.where(val_loader.dataset.mask_list == os.path.join(ann_dir, bu_name))\n",
    ")[0]\n",
    "\n",
    "raw_model_outputs(cr_idx, root, weight_path, category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26244f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"non-cell\"}\n",
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_Combined_CWRU_LBNL_ASU/\"\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_Combined_CWRU_LBNL_ASU/checkpoints/Fresh_Combined_CWRU_LBNL_ASU1/epoch_30/model.pt\"\n",
    "\n",
    "bu_name = \"bu_2_EL_18.09.2023-15-27-31_unknownID_ASU Minisample_SHJ1_91.npy\"\n",
    "cr_name = \"cr_2_EL_18.09.2023-15-27-31_unknownID_ASU Minisample_SHJ1_91.npy\"\n",
    "ann_dir = root + \"ann/val/\"\n",
    "val_dataset = load_dataset(root, channeled=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "cr_idx = np.ravel(\n",
    "    np.where(val_loader.dataset.mask_list == os.path.join(ann_dir, cr_name))\n",
    ")[0]\n",
    "bu_idx = np.ravel(\n",
    "    np.where(val_loader.dataset.mask_list == os.path.join(ann_dir, bu_name))\n",
    ")[0]\n",
    "\n",
    "\n",
    "clim = (0, 4)\n",
    "\n",
    "device, model = load_device_and_model(weight_path, category_mapping)\n",
    "\n",
    "# img, cr_mask = train_loader.dataset. __getitem__(cr_idx)\n",
    "# img, bu_mask = train_loader.dataset. __getitem__(bu_idx)\n",
    "\n",
    "img, cr_mask = val_loader.dataset.__getitem__(cr_idx)\n",
    "img, bu_mask = val_loader.dataset.__getitem__(bu_idx)\n",
    "\n",
    "cr_mask = functions.realign_mask(cr_mask)\n",
    "bu_mask = functions.realign_mask(bu_mask)\n",
    "img = img.to(device)\n",
    "\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "test_res_chan = model(img.unsqueeze(0)).detach().cpu().numpy().squeeze()\n",
    "test_res_act = sigmoid(test_res_chan)\n",
    "\n",
    "model_prediction = np.argmax(test_res_chan, axis=0)\n",
    "\n",
    "bu_layer = test_res_act[2]\n",
    "cr_layer = test_res_act[3]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, nrows=3, figsize=(10, 10), layout=\"compressed\")\n",
    "\n",
    "###\n",
    "# img, _ = train_loader.dataset.__getraw__(cr_idx)\n",
    "img, _ = val_loader.dataset.__getraw__(cr_idx)\n",
    "ax[0, 0].imshow(img, cmap=\"gray\", interpolation=\"None\")\n",
    "ax[0, 0].axis(\"off\")\n",
    "ax[0, 0].set_title(\"(a) EL image\", fontsize=\"xx-large\")\n",
    "###\n",
    "ax[0, 1].imshow(model_prediction, cmap=\"viridis\", clim=clim, interpolation=\"none\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "ax[0, 1].set_title(\"(b) Model Prediction\", fontsize=\"xx-large\")\n",
    "handles, labels = ax[0, 1].get_legend_handles_labels()\n",
    "cmap = mpl.colormaps[\"viridis\"].resampled(5)  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(5)]\n",
    "for c, classlabel in zip(cmaplist, [f\"({k}) {v}\" for k, v in category_mapping.items()]):\n",
    "    patch = mpatches.Patch(color=c, label=classlabel, ec=\"k\")\n",
    "    handles.append(patch)\n",
    "ax[0, 1].legend(handles=handles, fontsize=\"x-small\")\n",
    "###\n",
    "ax[1, 0].imshow(cr_mask, cmap=\"viridis\", interpolation=\"None\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "ax[1, 0].set_title(\"(c) Crack Target\", fontsize=\"xx-large\")\n",
    "handles, labels = ax[1, 0].get_legend_handles_labels()\n",
    "yellow_patch = mpatches.Patch(color=\"y\", label=\"Crack\", ec=\"k\")\n",
    "handles.append(yellow_patch)\n",
    "cyan_patch = mpatches.Patch(color=\"cyan\", label=\"Busbar\", ec=\"k\")\n",
    "handles.append(cyan_patch)\n",
    "ax[1, 0].legend(handles=handles)\n",
    "###\n",
    "ax[1, 1].imshow(bu_mask, cmap=\"viridis\", interpolation=\"None\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "ax[1, 1].set_title(\"(d) Busbar Target\", fontsize=\"xx-large\")\n",
    "handles, labels = ax[1, 1].get_legend_handles_labels()\n",
    "yellow_patch = mpatches.Patch(color=\"y\", label=\"Crack\", ec=\"k\")\n",
    "handles.append(yellow_patch)\n",
    "cyan_patch = mpatches.Patch(color=\"cyan\", label=\"Busbar\", ec=\"k\")\n",
    "handles.append(cyan_patch)\n",
    "ax[1, 1].legend(handles=handles)\n",
    "###\n",
    "ax[2, 0].imshow(cr_layer, cmap=\"viridis\", interpolation=\"None\")\n",
    "ax[2, 0].axis(\"off\")\n",
    "ax[2, 0].set_title(\"(e) Crack activation\", fontsize=\"xx-large\")\n",
    "###\n",
    "im = ax[2, 1].imshow(bu_layer, cmap=\"viridis\", interpolation=\"None\")\n",
    "ax[2, 1].axis(\"off\")\n",
    "ax[2, 1].set_title(\"(f) Busbar activation\", fontsize=\"xx-large\")\n",
    "fig.colorbar(im, ax=ax, label=\"Probability of classification\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvcracks (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
