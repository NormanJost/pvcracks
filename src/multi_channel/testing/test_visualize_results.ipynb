{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from utils import img_functions\n",
    "from utils.unet_model import construct_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root, channeled=True):\n",
    "    if channeled:\n",
    "        transformers = img_functions.Compose(\n",
    "            [\n",
    "                img_functions.ChanneledFixResize(256),\n",
    "                img_functions.ToTensor(),\n",
    "                img_functions.Normalize(),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        transformers = img_functions.Compose(\n",
    "            [\n",
    "                img_functions.FixResize(256),\n",
    "                img_functions.ToTensor(),\n",
    "                img_functions.Normalize(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    val_dataset = img_functions.SolarDataset(\n",
    "        root, image_folder=\"img/val\", mask_folder=\"ann/val\", transforms=transformers\n",
    "    )\n",
    "\n",
    "    return val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_device_and_model(weight_path):\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "    unet = construct_unet(len(category_mapping))\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "\n",
    "    checkpoint = torch.load(weight_path, map_location=device)\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint.items():\n",
    "        name = \"module.\" + k\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    unet.load_state_dict(new_state_dict)\n",
    "\n",
    "    model = unet.module.to(device)\n",
    "\n",
    "    return device, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(mask, raw_img, test_res, retrained, layers_to_render=None):\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    cmap = mpl.colormaps[\"viridis\"].resampled(5)  # define the colormap\n",
    "    cmaplist = [cmap(i) for i in range(5)]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12, 12))\n",
    "\n",
    "    ax[0].imshow(raw_img.convert(\"L\"), cmap=\"gray\", interpolation=\"None\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    clim = (0, 4)\n",
    "    ax[1].imshow(\n",
    "        mask_cpu,\n",
    "        cmap=\"viridis\",\n",
    "        clim=clim,\n",
    "    )\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "    if layers_to_render is not None:\n",
    "        test_res = np.where(np.isin(test_res, layers_to_render), test_res, 0)\n",
    "\n",
    "    ax[2].imshow(test_res, cmap=\"viridis\", clim=clim, interpolation=\"None\")\n",
    "    handles, labels = ax[2].get_legend_handles_labels()\n",
    "\n",
    "    for c, classlabel in zip(\n",
    "        cmaplist, [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "    ):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec=\"k\")\n",
    "        handles.append(patch)\n",
    "    ax[2].legend(handles=handles, fontsize=\"x-small\")\n",
    "    ax[2].axis(\"off\")\n",
    "    if retrained:\n",
    "        ax[2].set_title(\"Retrained Model Prediction\")\n",
    "    else:\n",
    "        ax[2].set_title(\"Model Prediction\")\n",
    "\n",
    "\n",
    "def show_two(mask, raw_img, test_res1, test_res2):\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    cmap = mpl.colormaps[\"viridis\"].resampled(5)  # define the colormap\n",
    "    cmaplist = [cmap(i) for i in range(5)]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=4, figsize=(12, 12))\n",
    "\n",
    "    ax[0].imshow(raw_img.convert(\"L\"), cmap=\"gray\", interpolation=\"None\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"EL Image\")\n",
    "\n",
    "    clim = (0, 4)\n",
    "    ax[1].imshow(mask_cpu, cmap=\"viridis\", clim=clim)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "    ax[2].imshow(test_res1, cmap=\"viridis\", clim=clim, interpolation=\"None\")\n",
    "    handles, labels = ax[2].get_legend_handles_labels()\n",
    "    for c, classlabel in zip(\n",
    "        cmaplist, [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "    ):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec=\"k\")\n",
    "        handles.append(patch)\n",
    "    ax[2].legend(handles=handles, fontsize=\"x-small\")\n",
    "    ax[2].axis(\"off\")\n",
    "    ax[2].set_title(\"Model Prediction\")\n",
    "\n",
    "    ax[3].imshow(test_res2, cmap=\"viridis\", clim=clim, interpolation=\"None\")\n",
    "    handles, labels = ax[2].get_legend_handles_labels()\n",
    "    for c, classlabel in zip(\n",
    "        cmaplist, [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "    ):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec=\"k\")\n",
    "        handles.append(patch)\n",
    "    ax[3].legend(handles=handles, fontsize=\"x-small\")\n",
    "    ax[3].axis(\"off\")\n",
    "    ax[3].set_title(\"Retrained Model Prediction\")\n",
    "\n",
    "\n",
    "def inference_and_show(\n",
    "    idx, root, weight_path, retrained=False, batch_size=1, layers_to_render=None\n",
    "):\n",
    "    val_dataset = load_dataset(root)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device, model = load_device_and_model(weight_path)\n",
    "\n",
    "    img, mask = val_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "    raw_img, _ = val_loader.dataset.__getraw__(idx)\n",
    "    test_res = model(img.unsqueeze(0)).detach().cpu().numpy().squeeze()\n",
    "    test_res = np.argmax(test_res, axis=0)\n",
    "\n",
    "    show(mask, raw_img, test_res, retrained, layers_to_render=layers_to_render)\n",
    "\n",
    "\n",
    "def inference_and_show_two(idx, root, weight_path1, weight_path2):\n",
    "    val_dataset = load_dataset(root)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    device, model1 = load_device_and_model(weight_path1)\n",
    "    device, model2 = load_device_and_model(weight_path2)\n",
    "\n",
    "    img, mask = val_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "    raw_img, _ = val_loader.dataset.__getraw__(idx)\n",
    "\n",
    "    test_res1 = model1(img.unsqueeze(0)).detach().cpu().numpy().squeeze()\n",
    "    test_res1 = np.argmax(test_res1, axis=0)\n",
    "\n",
    "    test_res2 = model2(img.unsqueeze(0)).detach().cpu().numpy().squeeze()\n",
    "    test_res2 = np.argmax(test_res2, axis=0)\n",
    "\n",
    "    show_two(mask, raw_img, test_res1, test_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_row_inference_and_show(idx, root, weight_path, threshold=0.5):\n",
    "    val_dataset = load_dataset(root)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    device, model = load_device_and_model(weight_path)\n",
    "\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = val_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # Get the raw image for display (assuming __getraw__ returns a PIL image)\n",
    "    raw_img, _ = val_loader.dataset.__getraw__(idx)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 4, H, W]\n",
    "    probs = torch.sigmoid(logits)  # shape: [1, 4, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [4, H, W]\n",
    "\n",
    "    # Ground truth is assumed to be already a 4-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [4, H, W]\n",
    "\n",
    "    # --- Visualization ---\n",
    "    # Create a grid with 3 rows and 4 columns:\n",
    "    #   Row 0: Raw image (displayed only once in the first column)\n",
    "    #   Row 1: Ground truth masks for each class\n",
    "    #   Row 2: Predicted masks for each class\n",
    "    n_classes = len(category_mapping)\n",
    "    class_names = [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "\n",
    "    fig, axs = plt.subplots(3, n_classes, figsize=(4 * n_classes, 12))\n",
    "\n",
    "    # Row 0: Display raw image in first subplot; hide other subplots in this row.\n",
    "    axs[0, 0].imshow(raw_img.convert(\"L\"), cmap=\"viridis\")\n",
    "    axs[0, 0].set_title(\"Raw Image\")\n",
    "    axs[0, 0].axis(\"off\")\n",
    "    for j in range(1, n_classes):\n",
    "        axs[0, j].axis(\"off\")\n",
    "\n",
    "    # Row 1: Ground truth for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[1, j].imshow(gt_mask[j], cmap=\"viridis\")\n",
    "        axs[1, j].set_title(f\"GT: {class_names[j]}\")\n",
    "        axs[1, j].axis(\"off\")\n",
    "\n",
    "    # Row 2: Predictions for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[2, j].imshow(pred_mask[j], cmap=\"viridis\")\n",
    "        axs[2, j].set_title(f\"Pred: {class_names[j]}\")\n",
    "        axs[2, j].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(\"Retrained Model Prediction\", fontsize=16)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference w/ Magic Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LineCorners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "# root = Path('/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/')\n",
    "# weight_path = '/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/checkpoints/retrain_corners_checkpoint3/epoch_30/model.pt'\n",
    "# root = Path(\"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CornersIHDEANE/\")\n",
    "# weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CornersIHDEANE/checkpoints/retrain_corners_checkpoint3/epoch_30/model.pt\"\n",
    "root = Path(\"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Norman_LineCorners/\")\n",
    "# weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Norman_LineCorners/checkpoints/line_corners_checkpoint2/epoch_30/model.pt\"\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Norman_LineCorners/checkpoints/line_corners_proper_data_checkpoint5/epoch_30/model.pt\"\n",
    "\n",
    "\n",
    "inference_and_show(1, root, weight_path)\n",
    "inference_and_show(2, root, weight_path)\n",
    "inference_and_show(3, root, weight_path)\n",
    "inference_and_show(4, root, weight_path)\n",
    "inference_and_show(5, root, weight_path)\n",
    "inference_and_show(6, root, weight_path)\n",
    "inference_and_show(7, root, weight_path)\n",
    "inference_and_show(18, root, weight_path)\n",
    "inference_and_show(30, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LineCorners on Original Weights (does not detect corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "root = Path(\"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/LineCorners_With_Original/\")\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/LineCorners_With_Original/checkpoints/line_corners_og_weights_checkpoint7/epoch_30/model.pt\"\n",
    "\n",
    "\n",
    "inference_and_show(1, root, weight_path)\n",
    "inference_and_show(2, root, weight_path)\n",
    "inference_and_show(3, root, weight_path)\n",
    "inference_and_show(4, root, weight_path)\n",
    "inference_and_show(5, root, weight_path)\n",
    "inference_and_show(6, root, weight_path)\n",
    "inference_and_show(7, root, weight_path)\n",
    "inference_and_show(18, root, weight_path)\n",
    "inference_and_show(30, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"busbar\", 2: \"dark\", 3: \"cross\", 4: \"dark\"}\n",
    "# my model\n",
    "root = Path(\"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CornersIHDEANE/\")\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CornersIHDEANE/checkpoints/retrain_corners_checkpoint3/epoch_30/model.pt\"\n",
    "\n",
    "inference_and_show(2, root, weight_path)\n",
    "inference_and_show(4, root, weight_path)\n",
    "inference_and_show(7, root, weight_path)\n",
    "inference_and_show(18, root, weight_path)\n",
    "inference_and_show(30, root, weight_path)\n",
    "inference_and_show(40, root, weight_path)\n",
    "inference_and_show(50, root, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emma's model\n",
    "category_mapping = {0: \"empty\", 1: \"busbar\", 2: \"dark\", 3: \"cross\", 4: \"dark\"}\n",
    "\n",
    "# root = Path('/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/')\n",
    "# weight_path = '/home/osanghi/pvcracks/retrained_pv-vision_model.pt'\n",
    "root = Path(\"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CornersIHDEANE/\")\n",
    "weight_path = (\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/retrained_pv-vision_model.pt\"\n",
    ")\n",
    "\n",
    "inference_and_show(18, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My model with no corners data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "\n",
    "# root = Path('/projects/wg-psel-ml/EL_images/osanghi/Norman_ELImages_NoCorners/')\n",
    "# weight_path = '/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/checkpoints/retrain_corners_checkpoint3/epoch_30/model.pt'\n",
    "\n",
    "# inference_and_show(1, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emma model w/ emma data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping = {0: \"empty\", 1: \"busbar\", 2: \"dark\", 3: \"cross\", 4: \"dark\"}\n",
    "\n",
    "# root = Path('/projects/wg-psel-ml/EL_images/eccoope')\n",
    "# weight_path = '/home/osanghi/pvcracks/retrained_pv-vision_model.pt'\n",
    "\n",
    "# inference_and_show(1, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OG weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = Path('/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE')\n",
    "# weight_path = '/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/checkpoints/retrain_corners_checkpoint3/epoch_30/model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_and_show(1, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CWRU_LBNL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/\"\n",
    ")\n",
    "\n",
    "weight_path1 = (\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/retrained_pv-vision_model.pt\"\n",
    ")\n",
    "weight_path2 = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/checkpoints/Combined_CWRU_SE_Dupont_and_LBNL_Mono2/epoch_30/Combined_CWRU_SE_Dupont_and_LBNL_Mono.pt\"\n",
    "# inference_and_show(20, root, weight_path, retrained=True)\n",
    "\n",
    "inference_and_show_two(20, root, weight_path1, weight_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/\"\n",
    ")\n",
    "\n",
    "weight_path1 = (\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/retrained_pv-vision_model.pt\"\n",
    ")\n",
    "weight_path2 = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/checkpoints/Combined_CWRU_SE_Dupont_and_LBNL_Mono2/epoch_30/Combined_CWRU_SE_Dupont_and_LBNL_Mono.pt\"\n",
    "\n",
    "# inference_and_show(110, root, weight_path, retrained=True)\n",
    "\n",
    "inference_and_show_two(110, root, weight_path1, weight_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/\"\n",
    ")\n",
    "\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/checkpoints/Combined_CWRU_SE_Dupont_and_LBNL_Mono2/epoch_30/Combined_CWRU_SE_Dupont_and_LBNL_Mono.pt\"\n",
    "\n",
    "inference_and_show(110, root, weight_path, retrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_LBNL_ASU_No_Busbar/\"\n",
    ")\n",
    "\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_LBNL_ASU_No_Busbar/checkpoints/Combined_CWRU_LBNL_ASU_No_Busbar1/epoch_30/Combined_CWRU_LBNL_ASU_No_Busbar.pt\"\n",
    "\n",
    "inference_and_show(24, root, weight_path, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "root = Path(\"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CWRU_Dupont_Mono/\")\n",
    "\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CWRU_Dupont_Mono/checkpoints/CWRU_Dupont_Mono1/epoch_30/CWRU_Dupont_Mono.pt\"\n",
    "\n",
    "inference_and_show(24, root, weight_path, retrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PVRW Poster Fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_two_pvrw(mask, raw_img, test_res1, test_res2):\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    cmap = mpl.colormaps[\"viridis\"].resampled(5)  # define the colormap\n",
    "    cmaplist = [cmap(i) for i in range(5)]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(12, 12))\n",
    "\n",
    "    clim = (0, 4)\n",
    "\n",
    "    ax[0, 0].imshow(raw_img.convert(\"L\"), cmap=\"gray\", interpolation=\"None\")\n",
    "    ax[0, 0].axis(\"off\")\n",
    "    ax[0, 0].set_title(\"EL Image\", fontsize=20)\n",
    "\n",
    "    ax[0, 1].imshow(mask_cpu, cmap=\"viridis\", clim=clim)\n",
    "    handles, labels = ax[0, 1].get_legend_handles_labels()\n",
    "    for c, classlabel in zip(\n",
    "        cmaplist, [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "    ):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec=\"k\")\n",
    "        handles.append(patch)\n",
    "    ax[0, 1].legend(handles=handles, fontsize=\"x-small\")\n",
    "    ax[0, 1].axis(\"off\")\n",
    "    ax[0, 1].set_title(\"Ground Truth Mask\", fontsize=20)\n",
    "\n",
    "    old_category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "    old_cmaplist = [cmaplist[i] for i in [0, 2, 3, 4, 1]]\n",
    "\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    old_cmap = mcolors.ListedColormap(old_cmaplist)\n",
    "\n",
    "    ax[1, 0].imshow(test_res1, cmap=old_cmap, clim=clim, interpolation=\"None\")\n",
    "    handles, labels = ax[1, 0].get_legend_handles_labels()\n",
    "    for c, classlabel in zip(\n",
    "        cmaplist, [f\"({k}) {v}\" for k, v in old_category_mapping.items()]\n",
    "    ):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec=\"k\")\n",
    "        handles.append(patch)\n",
    "    ax[1, 0].legend(handles=handles, fontsize=\"x-small\")\n",
    "    ax[1, 0].axis(\"off\")\n",
    "    ax[1, 0].set_title(\"Model Prediction\", fontsize=20)\n",
    "\n",
    "    ax[1, 1].imshow(test_res2, cmap=\"viridis\", clim=clim, interpolation=\"None\")\n",
    "    handles, labels = ax[1, 1].get_legend_handles_labels()\n",
    "    for c, classlabel in zip(\n",
    "        cmaplist, [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "    ):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec=\"k\")\n",
    "        handles.append(patch)\n",
    "    ax[1, 1].legend(handles=handles, fontsize=\"x-small\")\n",
    "    ax[1, 1].axis(\"off\")\n",
    "    ax[1, 1].set_title(\"Retrained Model Prediction\", fontsize=20)\n",
    "\n",
    "\n",
    "def inference_and_show_two_pvrw(idx, root, weight_path1, weight_path2):\n",
    "    val_dataset = load_dataset(root)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    device, model1 = load_device_and_model(weight_path1)\n",
    "    device, model2 = load_device_and_model(weight_path2)\n",
    "\n",
    "    img, mask = val_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "    raw_img, _ = val_loader.dataset.__getraw__(idx)\n",
    "\n",
    "    test_res1 = model1(img.unsqueeze(0)).detach().cpu().numpy().squeeze()\n",
    "    test_res1 = np.argmax(test_res1, axis=0)\n",
    "\n",
    "    test_res2 = model2(img.unsqueeze(0)).detach().cpu().numpy().squeeze()\n",
    "    test_res2 = np.argmax(test_res2, axis=0)\n",
    "\n",
    "    show_two_pvrw(mask, raw_img, test_res1, test_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"non-cell\"}\n",
    "\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/\"\n",
    ")\n",
    "\n",
    "weight_path1 = (\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/retrained_pv-vision_model.pt\"\n",
    ")\n",
    "weight_path2 = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SE_Dupont_and_LBNL_Mono/checkpoints/Combined_CWRU_SE_Dupont_and_LBNL_Mono2/epoch_30/Combined_CWRU_SE_Dupont_and_LBNL_Mono.pt\"\n",
    "# inference_and_show(20, root, weight_path, retrained=True)\n",
    "\n",
    "inference_and_show_two_pvrw(20, root, weight_path1, weight_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new figures for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"dark\", 1: \"busbar\", 2: \"crack\", 3: \"non-cell\"}\n",
    "\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty/\"\n",
    ")\n",
    "\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty_Optimized/model.pt\"\n",
    "# other_weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty/checkpoints/Channeled_Combined_CWRU_LBNL_ASU_No_Empty10/epoch_2/model.pt\"\n",
    "\n",
    "for i in range(0, 101):\n",
    "    two_row_inference_and_show(i, root, weight_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvcracks (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
