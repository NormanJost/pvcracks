{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953166f-9996-4024-82e6-24ddf3effbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "from utils import train_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_CWRU_Dupont/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_CWRU_SunEdison/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_LBNL/\"\n",
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU/\"\n",
    "\n",
    "\n",
    "model_weight_paths = {\n",
    "    \"emma_retrained\": \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/retrained_pv-vision_model.pt\",\n",
    "    \"original\": \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/pv-vision_model.pt\",\n",
    "}\n",
    "\n",
    "# weight_path = model_weight_paths[\"emma_retrained\"]\n",
    "weight_path = model_weight_paths[\"original\"]\n",
    "\n",
    "checkpoint_name = \"wandb_experiment_\" + root.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326df646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(pred, target, epsilon=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    dice = (2.0 * intersection + epsilon) / (union + epsilon)\n",
    "    return dice\n",
    "\n",
    "\n",
    "def iou_score(pred, target, epsilon=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_functions.load_dataset(root)\n",
    "device, model = train_functions.load_device_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7f34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"non-cell\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd228e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wandb_image(idx, threshold=0.5):\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = train_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 5, H, W]\n",
    "    probs = torch.sigmoid(logits)  # shape: [1, 5, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [5, H, W]\n",
    "\n",
    "    # Ground truth is assumed to be already a 5-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [5, H, W]\n",
    "\n",
    "    n_classes = len(category_mapping)\n",
    "\n",
    "    this_id_mask_images = []\n",
    "    for i in range(n_classes):\n",
    "        masks_dict = {\n",
    "            \"predictions\": {\n",
    "                \"mask_data\": pred_mask[i],\n",
    "                \"class_labels\": category_mapping,\n",
    "            },\n",
    "            \"ground_truth\": {\n",
    "                \"mask_data\": gt_mask[i],\n",
    "                \"class_labels\": category_mapping,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        mask_img = wandb.Image(\n",
    "            img,\n",
    "            masks=masks_dict,\n",
    "        )\n",
    "        this_id_mask_images.append(mask_img)\n",
    "    return this_id_mask_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9681c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wandb_image_for_table(idx, threshold=0.5):\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = train_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 5, H, W]\n",
    "    probs = torch.sigmoid(logits)  # shape: [1, 5, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [5, H, W]\n",
    "\n",
    "    # Ground truth is assumed to be already a 5-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [5, H, W]\n",
    "\n",
    "    n_classes = len(category_mapping)\n",
    "\n",
    "    this_id_table_info = []\n",
    "    this_id_table_info.append(wandb.Image(img))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        this_id_table_info.append(\n",
    "            wandb.Image(\n",
    "                img,\n",
    "                masks={\n",
    "                    \"ground_truth\": {\n",
    "                        \"mask_data\": gt_mask[i],\n",
    "                        \"class_labels\": {0: category_mapping[i]},\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        this_id_table_info.append(\n",
    "            wandb.Image(\n",
    "                img,\n",
    "                masks={\n",
    "                    \"predictions\": {\n",
    "                        \"mask_data\": pred_mask[i],\n",
    "                        \"class_labels\": {0: category_mapping[i]},\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return this_id_table_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f2288",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb9672-cea1-4261-86df-cc67308fc5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mojas-sanghi\u001b[0m (\u001b[33mojas-sanghi-university-of-arizona\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ojas/Desktop/saj/SANDIA/pvcracks/retrain/training/wandb/run-20250420_231111-pdpjuq1n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n' target=\"_blank\">dutiful-shape-40</a></strong> to <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = train_functions.get_save_dir(str(root), checkpoint_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "original_config = {\n",
    "    \"batch_size_train\": 8,\n",
    "    \"lr\": 0.00092234,\n",
    "    \"gamma\": 0.11727,\n",
    "    \"num_epochs\": 45,\n",
    "    \"batch_size_val\": 8,\n",
    "    \"criterion\": torch.nn.BCEWithLogitsLoss(),\n",
    "    # \"lr_scheduler_step_size\": 1,\n",
    "}\n",
    "\n",
    "config_serializable = original_config.copy()\n",
    "config_serializable[\"criterion\"] = str(config_serializable[\"criterion\"])\n",
    "\n",
    "with open(os.path.join(save_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_serializable, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"pvcracks\",\n",
    "    entity=\"ojas-sanghi-university-of-arizona\",\n",
    "    config=original_config,\n",
    ")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceacb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.batch_size_train, shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size_val, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b8831-e729-42c3-9eae-703af3d3001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=config.lr)\n",
    "# lr_scheduler = StepLR(optimizer, step_size=config.lr_scheduler_step_size, gamma=config.gamma)\n",
    "\n",
    "save_name = \"model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0725d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log gradients\n",
    "run.watch(model, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5a33b-f614-4c09-af94-1ab3de3f189d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Training Loss: 0.5101762526277183, Validation Loss: 0.43658209235771844\n",
      "Generating predictions for wandb...\n",
      "Logging to wandb...\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:49<00:49, 49.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model at epoch 1. \n",
      "\n",
      "Epoch 2/2, Training Loss: 0.40933988232543506, Validation Loss: 0.38161036242609436\n",
      "Generating predictions for wandb...\n",
      "Logging to wandb...\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:40<00:00, 50.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model at epoch 2. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "\n",
    "for epoch in tqdm(range(1, config.num_epochs + 1)):\n",
    "    training_step_loss = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # calc loss -- bce with logits loss applies sigmoid interally\n",
    "        training_loss = original_config[\"criterion\"](output, target)\n",
    "\n",
    "        # backward pass\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record loss\n",
    "        training_step_loss.append(training_loss.item())\n",
    "\n",
    "    training_epoch_loss.append(np.array(training_step_loss).mean())\n",
    "\n",
    "    val_step_loss = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.float()\n",
    "\n",
    "        # forward pass\n",
    "        data = data.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        # calc loss -- bce with logits loss applies sigmoid interally\n",
    "        val_loss = original_config[\"criterion\"](output, target)\n",
    "\n",
    "        val_step_loss.append(val_loss.item())\n",
    "\n",
    "    val_epoch_loss.append(np.array(val_step_loss).mean())\n",
    "    \n",
    "    # Compute dice and IoU metrics per channel\n",
    "    pred_probs = torch.sigmoid(output)\n",
    "    pred_binary = (pred_probs > 0.5).float()\n",
    "\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "\n",
    "    for i in range(pred_binary.size(1)):  # Loop over channels\n",
    "        dice = dice_coefficient(pred_binary[:, i], target[:, i])\n",
    "        iou = iou_score(pred_binary[:, i], target[:, i])\n",
    "        dice_scores.append(dice.item())\n",
    "        iou_scores.append(iou.item())\n",
    "\n",
    "    avg_dice = np.mean(dice_scores)\n",
    "    avg_iou = np.mean(iou_scores)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{config.num_epochs}, Training Loss: {np.array(training_step_loss).mean()}, Validation Loss: {np.array(val_step_loss).mean()}, Avg Dice: {avg_dice}, Avg IoU: {avg_iou}\"\n",
    "    )\n",
    "\n",
    "    # print(\"Generating predictions for wandb...\")\n",
    "    # mask_images = []\n",
    "    # table = wandb.Table(\n",
    "    #     columns=[\n",
    "    #         \"Image\",\n",
    "    #         \"GT Empty\",\n",
    "    #         \"Pred Empty\",\n",
    "    #         \"GT Dark\",\n",
    "    #         \"Pred Dark\",\n",
    "    #         \"GT Busbar\",\n",
    "    #         \"Pred Busbar\",\n",
    "    #         \"GT Crack\",\n",
    "    #         \"Pred Crack\",\n",
    "    #         \"GT Non-cell\",\n",
    "    #         \"Pred Non-cell\",\n",
    "    #     ]\n",
    "    # )\n",
    "    # for id in range(20):\n",
    "    #     mask_images.extend(create_wandb_image(id))\n",
    "    #     new_img_table = create_wandb_image_for_table(id)\n",
    "    #     table.add_data(*new_img_table)\n",
    "\n",
    "    print(\"Logging to wandb...\")\n",
    "    run.log(\n",
    "        {\n",
    "            \"train_loss\": np.array(training_step_loss).mean(),\n",
    "            \"val_loss\": np.array(val_step_loss).mean(),\n",
    "            # \"predictions\": mask_images,\n",
    "            # \"table\": table,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    table = wandb.Table(columns=[\"Image\"])\n",
    "\n",
    "    print(\"Saving model...\")\n",
    "    os.makedirs(os.path.join(save_dir, f\"epoch_{epoch}\"), exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f\"epoch_{epoch}\", save_name))\n",
    "    print(f\"Saved model at epoch {epoch}.\", end=\" \")\n",
    "\n",
    "    if epoch >= 2 and epoch < config.num_epochs:\n",
    "        os.remove(os.path.join(save_dir, f\"epoch_{epoch - 1}\", save_name))\n",
    "        print(f\"Removed model at epoch {epoch - 1}.\", end=\"\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06593fb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c27bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.40934</td></tr><tr><td>val_loss</td><td>0.38161</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-shape-40</strong> at: <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n</a><br> View project at: <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks</a><br>Synced 5 W&B file(s), 361 media file(s), 288 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250420_231111-pdpjuq1n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvcracks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
