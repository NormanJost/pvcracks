{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953166f-9996-4024-82e6-24ddf3effbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "from utils.unet_model import construct_unet\n",
    "from utils import img_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251c8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_CWRU_Dupont/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_CWRU_SunEdison/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_LBNL/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU/\"\n",
    "\n",
    "\n",
    "model_weight_paths = {\n",
    "    \"emma_retrained\": \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/retrained_pv-vision_model.pt\",\n",
    "    \"original\": \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/pv-vision_model.pt\",\n",
    "}\n",
    "\n",
    "# weight_path = model_weight_paths[\"emma_retrained\"]\n",
    "weight_path = model_weight_paths[\"original\"]\n",
    "\n",
    "checkpoint_name = \"wandb_experiment_\" + root.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b3df5-d827-4d5d-92a1-2c2fdcbef7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root):\n",
    "    transformers = img_functions.Compose(\n",
    "        [\n",
    "            img_functions.ChanneledFixResize(256),\n",
    "            img_functions.ToTensor(),\n",
    "            img_functions.Normalize(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_dataset = img_functions.SolarDataset(\n",
    "        root, image_folder=\"img/train\", mask_folder=\"ann/train\", transforms=transformers\n",
    "    )\n",
    "\n",
    "    val_dataset = img_functions.SolarDataset(\n",
    "        root, image_folder=\"img/val\", mask_folder=\"ann/val\", transforms=transformers\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d70c97-24fa-427a-8934-932d695a6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_device_and_model(weight_path):\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"mps\")\n",
    "    unet = construct_unet(5)\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "\n",
    "    model = unet.module.to(device)\n",
    "\n",
    "    return device, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a142ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_dir(base_dir, checkpoint_name):\n",
    "    checkpoint_dir = base_dir + \"/checkpoints/\"\n",
    "    folders = [folder for folder in os.listdir(checkpoint_dir)]\n",
    "\n",
    "    max_number = 0\n",
    "    for folder in folders:\n",
    "        number = int(folder[-1])\n",
    "        if number > max_number:\n",
    "            max_number = number\n",
    "\n",
    "    new_folder_name = f\"{checkpoint_name}{max_number + 1}\"\n",
    "    new_folder_path = os.path.join(checkpoint_dir, new_folder_name)\n",
    "\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eab99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = load_dataset(root)\n",
    "device, model = load_device_and_model(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7f34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"non-cell\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d889e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_inference_and_show(idx, threshold=0.5):\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = train_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # Get the raw image for display (assuming __getraw__ returns a PIL image)\n",
    "    raw_img, _ = train_loader.dataset.__getraw__(idx)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 5, H, W]\n",
    "    probs = torch.sigmoid(logits)  # shape: [1, 5, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [5, H, W]\n",
    "\n",
    "    # Ground truth is assumed to be already a 5-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [5, H, W]\n",
    "\n",
    "    # --- Visualization ---\n",
    "    # Create a grid with 3 rows and 5 columns:\n",
    "    #   Row 0: Raw image (displayed only once in the first column)\n",
    "    #   Row 1: Ground truth masks for each class\n",
    "    #   Row 2: Predicted masks for each class\n",
    "    n_classes = 5\n",
    "    class_names = [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "\n",
    "    fig, axs = plt.subplots(3, n_classes, figsize=(4 * n_classes, 12))\n",
    "\n",
    "    # Row 0: Display raw image in first subplot; hide other subplots in this row.\n",
    "    axs[0, 0].imshow(raw_img.convert(\"L\"), cmap=\"viridis\")\n",
    "    axs[0, 0].set_title(\"Raw Image\")\n",
    "    axs[0, 0].axis(\"off\")\n",
    "    for j in range(1, n_classes):\n",
    "        axs[0, j].axis(\"off\")\n",
    "\n",
    "    # Row 1: Ground truth for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[1, j].imshow(gt_mask[j], cmap=\"viridis\")\n",
    "        axs[1, j].set_title(f\"GT: {class_names[j]}\")\n",
    "        axs[1, j].axis(\"off\")\n",
    "\n",
    "    # Row 2: Predictions for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[2, j].imshow(pred_mask[j], cmap=\"viridis\")\n",
    "        axs[2, j].set_title(f\"Pred: {class_names[j]}\")\n",
    "        axs[2, j].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(\"Retrained Model Prediction\", fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd228e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wandb_image(idx, threshold=0.5):\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = train_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 5, H, W]\n",
    "    probs = torch.sigmoid(logits)  # shape: [1, 5, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [5, H, W]\n",
    "\n",
    "    # Ground truth is assumed to be already a 5-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [5, H, W]\n",
    "\n",
    "    n_classes = len(category_mapping)\n",
    "\n",
    "    this_id_mask_images = []\n",
    "    for i in range(n_classes):\n",
    "        masks_dict = {\n",
    "            \"predictions\": {\n",
    "                \"mask_data\": pred_mask[i],\n",
    "                \"class_labels\": category_mapping,\n",
    "            },\n",
    "            \"ground_truth\": {\n",
    "                \"mask_data\": gt_mask[i],\n",
    "                \"class_labels\": category_mapping,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        mask_img = wandb.Image(\n",
    "            img,\n",
    "            masks=masks_dict,\n",
    "        )\n",
    "        this_id_mask_images.append(mask_img)\n",
    "    return this_id_mask_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9681c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wandb_image_for_table(idx, threshold=0.5):\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = train_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 5, H, W]\n",
    "    probs = torch.sigmoid(logits)  # shape: [1, 5, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [5, H, W]\n",
    "\n",
    "    # Ground truth is assumed to be already a 5-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [5, H, W]\n",
    "\n",
    "    n_classes = len(category_mapping)\n",
    "\n",
    "    this_id_table_info = []\n",
    "    this_id_table_info.append(wandb.Image(img))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        this_id_table_info.append(\n",
    "            wandb.Image(\n",
    "                img,\n",
    "                masks={\n",
    "                    \"ground_truth\": {\n",
    "                        \"mask_data\": gt_mask[i],\n",
    "                        \"class_labels\": {0: category_mapping[i]},\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        this_id_table_info.append(\n",
    "            wandb.Image(\n",
    "                img,\n",
    "                masks={\n",
    "                    \"predictions\": {\n",
    "                        \"mask_data\": pred_mask[i],\n",
    "                        \"class_labels\": {0: category_mapping[i]},\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return this_id_table_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f2288",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74bb9672-cea1-4261-86df-cc67308fc5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mojas-sanghi\u001b[0m (\u001b[33mojas-sanghi-university-of-arizona\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ojas/Desktop/saj/SANDIA/pvcracks/retrain/training/wandb/run-20250420_231111-pdpjuq1n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n' target=\"_blank\">dutiful-shape-40</a></strong> to <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = get_save_dir(str(root), checkpoint_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"batch_size_val\": 4,\n",
    "    \"batch_size_train\": 4,\n",
    "    \"lr\": 1e-4,\n",
    "    \"step_size\": 1,\n",
    "    \"gamma\": 0.1,\n",
    "    \"num_epochs\": 2,\n",
    "    \"criterion\": torch.nn.BCEWithLogitsLoss(),\n",
    "}\n",
    "\n",
    "config_serializable = config.copy()\n",
    "config_serializable[\"criterion\"] = str(config_serializable[\"criterion\"])\n",
    "\n",
    "with open(os.path.join(save_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_serializable, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"pvcracks\", entity=\"ojas-sanghi-university-of-arizona\", config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ceacb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"batch_size_train\"], shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size_val\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "899b8831-e729-42c3-9eae-703af3d3001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=config[\"lr\"])\n",
    "# lr_scheduler = StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"gamma\"])\n",
    "\n",
    "save_name = \"model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0725d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log gradients\n",
    "run.watch(model, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b5a33b-f614-4c09-af94-1ab3de3f189d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Training Loss: 0.5101762526277183, Validation Loss: 0.43658209235771844\n",
      "Generating predictions for wandb...\n",
      "Logging to wandb...\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:49<00:49, 49.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model at epoch 1. \n",
      "\n",
      "Epoch 2/2, Training Loss: 0.40933988232543506, Validation Loss: 0.38161036242609436\n",
      "Generating predictions for wandb...\n",
      "Logging to wandb...\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:40<00:00, 50.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model at epoch 2. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "\n",
    "for epoch in tqdm(range(1, config[\"num_epochs\"] + 1)):\n",
    "    training_step_loss = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # calc loss -- bce with logits loss applies sigmoid interally\n",
    "        training_loss = config[\"criterion\"](output, target)\n",
    "\n",
    "        # backward pass\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record loss\n",
    "        training_step_loss.append(training_loss.item())\n",
    "\n",
    "    training_epoch_loss.append(np.array(training_step_loss).mean())\n",
    "\n",
    "    val_step_loss = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.float()\n",
    "\n",
    "        # forward pass\n",
    "        data = data.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        # calc loss -- bce with logits loss applies sigmoid interally\n",
    "        val_loss = config[\"criterion\"](output, target)\n",
    "\n",
    "        val_step_loss.append(val_loss.item())\n",
    "\n",
    "    val_epoch_loss.append(np.array(val_step_loss).mean())\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{config['num_epochs']}, Training Loss: {np.array(training_step_loss).mean()}, Validation Loss: {np.array(val_step_loss).mean()}\"\n",
    "    )\n",
    "\n",
    "    print(\"Generating predictions for wandb...\")\n",
    "    mask_images = []\n",
    "    table = wandb.Table(\n",
    "        columns=[\n",
    "            \"Image\",\n",
    "            \"GT Empty\",\n",
    "            \"Pred Empty\",\n",
    "            \"GT Dark\",\n",
    "            \"Pred Dark\",\n",
    "            \"GT Busbar\",\n",
    "            \"Pred Busbar\",\n",
    "            \"GT Crack\",\n",
    "            \"Pred Crack\",\n",
    "            \"GT Non-cell\",\n",
    "            \"Pred Non-cell\",\n",
    "        ]\n",
    "    )\n",
    "    for id in range(20):\n",
    "        mask_images.extend(create_wandb_image(id))\n",
    "        new_img_table = create_wandb_image_for_table(id)\n",
    "        table.add_data(*new_img_table)\n",
    "\n",
    "    print(\"Logging to wandb...\")\n",
    "    run.log(\n",
    "        {\n",
    "            \"train_loss\": np.array(training_step_loss).mean(),\n",
    "            \"val_loss\": np.array(val_step_loss).mean(),\n",
    "            \"predictions\": mask_images,\n",
    "            \"table\": table,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    table = wandb.Table(columns=[\"Image\"])\n",
    "\n",
    "    print(\"Saving model...\")\n",
    "    os.makedirs(os.path.join(save_dir, f\"epoch_{epoch}\"), exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f\"epoch_{epoch}\", save_name))\n",
    "    print(f\"Saved model at epoch {epoch}.\", end=\" \")\n",
    "\n",
    "    if epoch >= 2 and epoch < config[\"num_epochs\"]:\n",
    "        os.remove(os.path.join(save_dir, f\"epoch_{epoch - 1}\", save_name))\n",
    "        print(f\"Removed model at epoch {epoch - 1}.\", end=\"\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06593fb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c27bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.40934</td></tr><tr><td>val_loss</td><td>0.38161</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-shape-40</strong> at: <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks/runs/pdpjuq1n</a><br> View project at: <a href='https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks' target=\"_blank\">https://wandb.ai/ojas-sanghi-university-of-arizona/pvcracks</a><br>Synced 5 W&B file(s), 361 media file(s), 288 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250420_231111-pdpjuq1n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvcracks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
