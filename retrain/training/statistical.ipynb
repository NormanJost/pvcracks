{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import DataParallel\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from imutils.paths import list_images, list_files\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "\n",
    "pv_vision_dir = os.path.join(Path.home(), 'pv-vision')\n",
    "functions_dir = os.path.join(Path.home(), 'el_img_cracks_ec')\n",
    "\n",
    "sys.path.append(pv_vision_dir)\n",
    "sys.path.append(functions_dir)\n",
    "import functions\n",
    "\n",
    "from pv_vision.nn import ModelHandler\n",
    "from tutorials.unet_model import construct_unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analysis of class representation in our training set vs. LBNL's training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_map = {0 : 'empty',\n",
    "          1 : 'busbar',\n",
    "          2 : 'crack',\n",
    "          3 : 'cross',\n",
    "          4 : 'dark'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will put this method into util in the future\n",
    "class SolarDataset(VisionDataset):\n",
    "    \"\"\"A dataset directly read images and masks from folder.    \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 image_folder, \n",
    "                 mask_folder,\n",
    "                 transforms,\n",
    "                 mode = \"train\",\n",
    "                 random_seed=42):\n",
    "        super().__init__(root, transforms)\n",
    "        self.image_path = Path(self.root) / image_folder\n",
    "        self.mask_path = Path(self.root) / mask_folder\n",
    "\n",
    "        if not os.path.exists(self.image_path):\n",
    "            raise OSError(f\"{self.image_path} not found.\")\n",
    "\n",
    "        if not os.path.exists(self.mask_path):\n",
    "            raise OSError(f\"{self.mask_path} not found.\")\n",
    "\n",
    "        self.image_list = sorted(list(list_images(self.image_path)))\n",
    "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
    "\n",
    "        self.image_list = np.array(self.image_list)\n",
    "        self.mask_list = np.array(self.mask_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getname__(self, index):\n",
    "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
    "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
    "\n",
    "        if image_name == mask_name:\n",
    "            return image_name\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __getraw__(self, index):\n",
    "        if not self.__getname__(index):\n",
    "            raise ValueError(\"{}: Image doesn't match with mask\".format(os.path.split(self.image_list[index])[-1]))\n",
    "        image = Image.open(self.image_list[index])\n",
    "        mask = Image.open(self.mask_list[index]).convert('L')\n",
    "        mask = np.array(mask)\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, mask = self.__getraw__(index)\n",
    "        image, mask = self.transforms(image, mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# will put into utils in the future\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        \"\"\"\n",
    "        transforms: a list of transform\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        \"\"\"\n",
    "        image: input image\n",
    "        target: input mask\n",
    "        \"\"\"\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "class FixResize:\n",
    "    # UNet requires input size to be multiple of 16\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        return image, target\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\"Transform the image to tensor. Scale the image to [0,1] float32.\n",
    "    Transform the mask to tensor.\n",
    "    \"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = transforms.ToTensor()(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "class PILToTensor:\n",
    "    \"\"\"Transform the image to tensor. Keep raw type.\"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = F.pil_to_tensor(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "class Normalize:\n",
    "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analysis of class representation for LBNL's training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/home/eccoope/pv-vision/examples/crack_segmentation/img_label_for_training')\n",
    "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
    "trainset = SolarDataset(root, image_folder=\"train/img\", \n",
    "        mask_folder=\"train/ann\", transforms=transformers)\n",
    "\n",
    "my_index = [trainset.__getname__(i) for i in range(len(trainset.image_list))]\n",
    "\n",
    "df = pd.DataFrame(index=my_index, columns=[str(i) for i in range(5)])\n",
    "\n",
    "for i in range(len(my_index)):\n",
    "    name = trainset. __getname__(i)\n",
    "    img, mask = trainset. __getitem__(i)\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    vals, counts = np.unique(mask_cpu, return_counts=True)\n",
    "\n",
    "    for v, c in zip(vals, counts):\n",
    "        df.at[name, str(v)] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of images include Class 0 (empty)\n",
      "20.88% of images include Class 1 (busbar)\n",
      "25.1% of images include Class 2 (crack)\n",
      "39.2% of images include Class 3 (cross)\n",
      "100.0% of images include Class 4 (dark)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    counts = len(df[~df[str(i)].isna()])\n",
    "    pct = counts/len(df)\n",
    "    print(f'{np.round(100*pct,2)}% of images include Class {i} ({my_map[i]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.67% of images with Class 1 (busbar) also contain Class 2 (crack)\n",
      "99.51% of images with Class 1 (busbar) also contain Class 3 (cross)\n",
      "\n",
      "\n",
      "46.31% of images with Class 2 (crack) also contain Class 1 (busbar)\n",
      "84.84% of images with Class 2 (crack) also contain Class 3 (cross)\n",
      "\n",
      "\n",
      "53.02% of images with Class 3 (cross) also contain Class 1 (busbar)\n",
      "54.33% of images with Class 3 (cross) also contain Class 2 (crack)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    for j in range(1, 4):\n",
    "        \n",
    "        if i == j:\n",
    "            continue\n",
    "        else:\n",
    "            base = df[~df[str(i)].isna()]\n",
    "            test = df[(~df[str(i)].isna()) & (~df[str(j)].isna())]\n",
    "            pct = len(test)/len(base)\n",
    "            print(f'{np.round(100*pct, 2)}% of images with Class {i} ({my_map[i]}) also contain Class {j} ({my_map[j]})')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analysis of class representation for our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/projects/wg-psel-ml/EL_images/eccoope')\n",
    "transformers = functions.Compose([functions.FixResize(256), functions.ToTensor(), functions.Normalize()])\n",
    "trainset = functions.SolarDataset(root, image_folder=\"img/train\", \n",
    "        mask_folder=\"ann/train\", transforms=transformers)\n",
    "valset = functions.SolarDataset(root, image_folder=\"img/val\", \n",
    "        mask_folder=\"ann/val\", transforms=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index = [trainset.__getname__(i) for i in range(len(trainset.image_list))]\n",
    "\n",
    "df2 = pd.DataFrame(index=my_index, columns=[str(i) for i in range(5)])\n",
    "\n",
    "for i in range(len(my_index)):\n",
    "    name = trainset. __getname__(i)\n",
    "    img, mask = trainset. __getitem__(i)\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    vals, counts = np.unique(mask_cpu, return_counts=True)\n",
    "\n",
    "    for v, c in zip(vals, counts):\n",
    "        df2.at[name, str(v)] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of images include Class 0 (empty)\n",
      "100.0% of images include Class 1 (busbar)\n",
      "43.8% of images include Class 2 (crack)\n",
      "1.55% of images include Class 3 (cross)\n",
      "45.35% of images include Class 4 (dark)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    counts = len(df2[~df2[str(i)].isna()])\n",
    "    pct = counts/len(df2)\n",
    "    print(f'{np.round(100*pct,2)}% of images include Class {i} ({my_map[i]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.8% of images with Class 1 (busbar) also contain Class 2 (crack)\n",
      "1.55% of images with Class 1 (busbar) also contain Class 3 (cross)\n",
      "\n",
      "\n",
      "100.0% of images with Class 2 (crack) also contain Class 1 (busbar)\n",
      "0.0% of images with Class 2 (crack) also contain Class 3 (cross)\n",
      "\n",
      "\n",
      "100.0% of images with Class 3 (cross) also contain Class 1 (busbar)\n",
      "0.0% of images with Class 3 (cross) also contain Class 2 (crack)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    for j in range(1, 4):\n",
    "        \n",
    "        if i == j:\n",
    "            continue\n",
    "        else:\n",
    "            base = df2[~df2[str(i)].isna()]\n",
    "            test = df2[(~df2[str(i)].isna()) & (~df2[str(j)].isna())]\n",
    "            pct = len(test)/len(base)\n",
    "            print(f'{np.round(100*pct, 2)}% of images with Class {i} ({my_map[i]}) also contain Class {j} ({my_map[j]})')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmenv",
   "language": "python",
   "name": "dmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
