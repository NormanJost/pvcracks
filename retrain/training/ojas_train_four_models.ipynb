{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953166f-9996-4024-82e6-24ddf3effbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# pv_vision_dir = os.path.join(Path.home(), 'pv-vision')\n",
    "pv_vision_dir = os.path.join('/home/eccoope', 'pv-vision')\n",
    "# functions_dir = os.path.join(Path.home(), 'el_img_cracks_ec', 'scripts')\n",
    "functions_dir = os.path.join('/home/eccoope', 'el_img_cracks_ec', 'scripts')\n",
    "\n",
    "sys.path.append(pv_vision_dir)\n",
    "sys.path.append(functions_dir)\n",
    "\n",
    "# ojas_functions_dir = os.path.join(Path.home(), 'pvcracks/retrain/')\n",
    "ojas_functions_dir = '/Users/ojas/Desktop/saj/SANDIA/pvcracks/retrain/'\n",
    "sys.path.append(ojas_functions_dir)\n",
    "\n",
    "from tutorials.unet_model import construct_unet\n",
    "import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = Path('/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/')\n",
    "# root = Path('/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CornersIHDEANE/')\n",
    "# root = Path('/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Norman_LineCorners/')\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/LineCorners_With_Original/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CWRU_SunEdison_Mono/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/CWRU_Dupont_Mono/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_SunEdison_and_Dupont_Mono/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/LBNL_Mono_Cells/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Combined_CWRU_LBNL_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/ASU_IHDEANE/\"\n",
    "\n",
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_Combined_CWRU_LBNL_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_CWRU_SunEdison/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_LBNL/\"\n",
    "\n",
    "model_weight_paths = {\n",
    "    \"emma_retrained\": \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/retrained_pv-vision_model.pt\",\n",
    "    \"original\": \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/pv-vision_model.pt\",\n",
    "}\n",
    "\n",
    "# weight_path = model_weight_paths[\"emma_retrained\"]\n",
    "weight_path = model_weight_paths[\"original\"]\n",
    "\n",
    "# checkpoint_name = \"line_corners_og_weights_checkpoint\"\n",
    "# checkpoint_name = \"CWRU_SunEdison_Mono\"\n",
    "# checkpoint_name = \"CWRU_Dupont_Mono\"\n",
    "# checkpoint_name = \"Combined_CWRU_SunEdison_and_Dupont_Mono\"\n",
    "# checkpoint_name = \"LBNL_Mono_Cells\"\n",
    "# checkpoint_name = \"Combined_CWRU_LBNL_ASU\"\n",
    "\n",
    "checkpoint_name = \"Fresh_Combined_CWRU_LBNL_ASU\"\n",
    "# checkpoint_name = \"Fresh_CWRU_SunEdison\"\n",
    "# checkpoint_name = \"Fresh_ASU\"\n",
    "# checkpoint_name = \"Fresh_LBNL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b3df5-d827-4d5d-92a1-2c2fdcbef7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root):\n",
    "    transformers = functions.Compose([functions.FixResize(256), functions.ToTensor(), functions.Normalize()])\n",
    "    \n",
    "    train_dataset = functions.SolarDataset(root, image_folder=\"img/train\", \n",
    "            mask_folder=\"ann/train\", transforms=transformers)\n",
    "    \n",
    "    val_dataset = functions.SolarDataset(root, image_folder=\"img/val\", \n",
    "            mask_folder=\"ann/val\", transforms=transformers)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d70c97-24fa-427a-8934-932d695a6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_device_and_model(weight_path):\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"mps\")\n",
    "    unet = construct_unet(5)\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "    \n",
    "    checkpoint = torch.load(weight_path, map_location=device)\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    if weight_path == model_weight_paths[\"emma_retrained\"]:\n",
    "        for k, v in checkpoint.items():\n",
    "            name = \"module.\" + k\n",
    "            new_state_dict[name] = v\n",
    "    elif weight_path == model_weight_paths[\"original\"]:\n",
    "        for k, v in checkpoint.items():\n",
    "            new_state_dict[k] = v\n",
    "    \n",
    "    unet.load_state_dict(new_state_dict)\n",
    "\n",
    "    model = unet.module.to(device)\n",
    "    \n",
    "    return device, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_save_dir(base_dir, checkpoint_name):\n",
    "    checkpoint_dir = base_dir + \"/checkpoints/\"\n",
    "    checkpoint_dir_path = Path(checkpoint_dir)\n",
    "    folders = [folder.name for folder in checkpoint_dir_path.iterdir() if folder.is_dir()]    \n",
    "    \n",
    "    max_number = 0\n",
    "    for folder in folders:\n",
    "        number = int(folder[-1])\n",
    "        if number > max_number:\n",
    "            max_number = number\n",
    "\n",
    "    new_folder_name = f\"{checkpoint_name}{max_number + 1}\"\n",
    "    new_folder_path = os.path.join(checkpoint_dir, new_folder_name)\n",
    "    \n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    \n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = load_dataset(root)\n",
    "device, model = load_device_and_model(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb9672-cea1-4261-86df-cc67308fc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val=1\n",
    "batch_size_train=1\n",
    "lr = 0.000001\n",
    "step_size=1\n",
    "gamma = 0.1\n",
    "num_epochs = 30\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "\n",
    "save_dir = get_save_dir(str(root), checkpoint_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "params_dict = {'batch_size_val' : batch_size_val,\n",
    "           'batch_size_train' : batch_size_train,\n",
    "           'lr' : lr,\n",
    "           'step_size' : step_size,\n",
    "           'gamma' : gamma,\n",
    "           'num_epochs' : num_epochs,\n",
    "           'criterion' : str(criterion)}\n",
    "\n",
    "with open(os.path.join(save_dir, 'params.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(params_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b8831-e729-42c3-9eae-703af3d3001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "lr_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "evaluate_metric=None\n",
    "running_record = {'train': {'loss': []}, 'val': {'loss': []}}\n",
    "\n",
    "save_name='model.pt'\n",
    "cache_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "# category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"non-cell area\"}\n",
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"non-cell\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_and_show(idx, retrained=False):\n",
    "    img, mask = train_loader.dataset. __getitem__(idx)\n",
    "    img = img.to(device)\n",
    "    raw_img, _ = train_loader.dataset. __getraw__(idx)\n",
    "    test_res = model(img.unsqueeze(0)).detach().cpu().numpy().squeeze()#.argmax(axis = 0)\n",
    "    test_res = np.argmax(test_res, axis = 0)\n",
    "\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    cmap = mpl.colormaps['viridis'].resampled(5)  # define the colormap\n",
    "    cmaplist = [cmap(i) for i in range(5)]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12,12))\n",
    "\n",
    "    im = ax[0].imshow(raw_img.convert('L'), cmap='gray', interpolation='None')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    clim = (0, 4)\n",
    "    im = ax[1].imshow(mask_cpu, cmap = 'viridis', clim=clim)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "    ax[2].imshow(test_res, cmap = 'viridis', clim = clim, interpolation='None')\n",
    "    handles, labels = ax[2].get_legend_handles_labels()\n",
    "\n",
    "    for c, classlabel in zip(cmaplist, [f'({k}) {v}' for k, v in category_mapping.items()]):\n",
    "            patch = mpatches.Patch(color=c, label=classlabel, ec='k')\n",
    "            handles.append(patch)\n",
    "    ax[2].legend(handles=handles, fontsize='x-small')\n",
    "    ax[2].axis('off')\n",
    "    if retrained:\n",
    "        ax[2].set_title(\"Retrained Model Prediction\")\n",
    "    else:\n",
    "        ax[2].set_title(\"Model Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f2288",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5a33b-f614-4c09-af94-1ab3de3f189d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    \n",
    "    training_step_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        output_activated = 1 /(1 + torch.exp(-output))\n",
    "        target_onehot = torch.nn.functional.one_hot(target, num_classes = 5)\n",
    "        target_onehot = torch.moveaxis(target_onehot, 3, 1)\n",
    "        \n",
    "        training_loss = criterion(output_activated, target_onehot.float())\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        training_step_loss.append(training_loss.item())\n",
    "        \n",
    "    training_epoch_loss.append(np.array(training_step_loss).mean())\n",
    "        \n",
    "    val_step_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        output_activated = 1 /(1 + torch.exp(-output))\n",
    "        target_onehot = torch.nn.functional.one_hot(target, num_classes = 5)\n",
    "        target_onehot = torch.moveaxis(target_onehot, 3, 1)\n",
    "        val_loss = criterion(output_activated, target_onehot.float())\n",
    "        \n",
    "        val_step_loss.append(val_loss.item())\n",
    "        \n",
    "    val_epoch_loss.append(np.array(val_step_loss).mean())\n",
    "    \n",
    "    os.makedirs(os.path.join(save_dir, f'epoch_{epoch}'), exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f'epoch_{epoch}', save_name))\n",
    "    print(f'Saved model at epoch {epoch}')\n",
    "    \n",
    "    if epoch >= 2 and epoch < 30:\n",
    "        os.remove(os.path.join(save_dir, f'epoch_{epoch-1}', save_name))\n",
    "        print(f'Removed model at epoch {epoch-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff04e5-394c-481b-b754-164b2d935291",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(-32, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec13f11-7eaa-4f7d-8dc7-0fb411914209",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(13, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe0d75-7a6f-40b7-b502-f714d541ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(44, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(1, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a9bfe-7b09-4a7a-8718-fc779cb8b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(1, len(training_epoch_loss) + 1, 1)\n",
    "\n",
    "ax.scatter(x, training_epoch_loss, label='training loss')\n",
    "ax.scatter(x, val_epoch_loss, label='validation loss')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "\n",
    "print(training_epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bccc5b6",
   "metadata": {},
   "source": [
    "# SECOND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_Combined_CWRU_LBNL_ASU/\"\n",
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_CWRU_SunEdison/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_LBNL/\"\n",
    "\n",
    "# checkpoint_name = \"Fresh_Combined_CWRU_LBNL_ASU\"\n",
    "checkpoint_name = \"Fresh_CWRU_SunEdison\"\n",
    "# checkpoint_name = \"Fresh_ASU\"\n",
    "# checkpoint_name = \"Fresh_LBNL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = load_dataset(root)\n",
    "device, model = load_device_and_model(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val=1\n",
    "batch_size_train=1\n",
    "lr = 0.000001\n",
    "step_size=1\n",
    "gamma = 0.1\n",
    "num_epochs = 30\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "\n",
    "save_dir = get_save_dir(str(root), checkpoint_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "params_dict = {'batch_size_val' : batch_size_val,\n",
    "           'batch_size_train' : batch_size_train,\n",
    "           'lr' : lr,\n",
    "           'step_size' : step_size,\n",
    "           'gamma' : gamma,\n",
    "           'num_epochs' : num_epochs,\n",
    "           'criterion' : str(criterion)}\n",
    "\n",
    "with open(os.path.join(save_dir, 'params.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(params_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35cc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "lr_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "evaluate_metric=None\n",
    "running_record = {'train': {'loss': []}, 'val': {'loss': []}}\n",
    "\n",
    "save_name='model.pt'\n",
    "cache_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    \n",
    "    training_step_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        output_activated = 1 /(1 + torch.exp(-output))\n",
    "        target_onehot = torch.nn.functional.one_hot(target, num_classes = 5)\n",
    "        target_onehot = torch.moveaxis(target_onehot, 3, 1)\n",
    "        \n",
    "        training_loss = criterion(output_activated, target_onehot.float())\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        training_step_loss.append(training_loss.item())\n",
    "        \n",
    "    training_epoch_loss.append(np.array(training_step_loss).mean())\n",
    "        \n",
    "    val_step_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        output_activated = 1 /(1 + torch.exp(-output))\n",
    "        target_onehot = torch.nn.functional.one_hot(target, num_classes = 5)\n",
    "        target_onehot = torch.moveaxis(target_onehot, 3, 1)\n",
    "        val_loss = criterion(output_activated, target_onehot.float())\n",
    "        \n",
    "        val_step_loss.append(val_loss.item())\n",
    "        \n",
    "    val_epoch_loss.append(np.array(val_step_loss).mean())\n",
    "    \n",
    "    os.makedirs(os.path.join(save_dir, f'epoch_{epoch}'), exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f'epoch_{epoch}', save_name))\n",
    "    print(f'Saved model at epoch {epoch}')\n",
    "    \n",
    "    if epoch >= 2 and epoch < 30:\n",
    "        os.remove(os.path.join(save_dir, f'epoch_{epoch-1}', save_name))\n",
    "        print(f'Removed model at epoch {epoch-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4316848",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(-32, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(13, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01acb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(44, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b127e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(1, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f07f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(1, len(training_epoch_loss) + 1, 1)\n",
    "\n",
    "ax.scatter(x, training_epoch_loss, label='training loss')\n",
    "ax.scatter(x, val_epoch_loss, label='validation loss')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "\n",
    "print(training_epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7856ba4",
   "metadata": {},
   "source": [
    "## THIRD TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92684468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_Combined_CWRU_LBNL_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_CWRU_SunEdison/\"\n",
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_LBNL/\"\n",
    "\n",
    "# checkpoint_name = \"Fresh_Combined_CWRU_LBNL_ASU\"\n",
    "# checkpoint_name = \"Fresh_CWRU_SunEdison\"\n",
    "checkpoint_name = \"Fresh_ASU\"\n",
    "# checkpoint_name = \"Fresh_LBNL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = load_dataset(root)\n",
    "device, model = load_device_and_model(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val=1\n",
    "batch_size_train=1\n",
    "lr = 0.000001\n",
    "step_size=1\n",
    "gamma = 0.1\n",
    "num_epochs = 30\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "\n",
    "save_dir = get_save_dir(str(root), checkpoint_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "params_dict = {'batch_size_val' : batch_size_val,\n",
    "           'batch_size_train' : batch_size_train,\n",
    "           'lr' : lr,\n",
    "           'step_size' : step_size,\n",
    "           'gamma' : gamma,\n",
    "           'num_epochs' : num_epochs,\n",
    "           'criterion' : str(criterion)}\n",
    "\n",
    "with open(os.path.join(save_dir, 'params.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(params_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "lr_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "evaluate_metric=None\n",
    "running_record = {'train': {'loss': []}, 'val': {'loss': []}}\n",
    "\n",
    "save_name='model.pt'\n",
    "cache_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    \n",
    "    training_step_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        output_activated = 1 /(1 + torch.exp(-output))\n",
    "        target_onehot = torch.nn.functional.one_hot(target, num_classes = 5)\n",
    "        target_onehot = torch.moveaxis(target_onehot, 3, 1)\n",
    "        \n",
    "        training_loss = criterion(output_activated, target_onehot.float())\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        training_step_loss.append(training_loss.item())\n",
    "        \n",
    "    training_epoch_loss.append(np.array(training_step_loss).mean())\n",
    "        \n",
    "    val_step_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        output_activated = 1 /(1 + torch.exp(-output))\n",
    "        target_onehot = torch.nn.functional.one_hot(target, num_classes = 5)\n",
    "        target_onehot = torch.moveaxis(target_onehot, 3, 1)\n",
    "        val_loss = criterion(output_activated, target_onehot.float())\n",
    "        \n",
    "        val_step_loss.append(val_loss.item())\n",
    "        \n",
    "    val_epoch_loss.append(np.array(val_step_loss).mean())\n",
    "    \n",
    "    os.makedirs(os.path.join(save_dir, f'epoch_{epoch}'), exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f'epoch_{epoch}', save_name))\n",
    "    print(f'Saved model at epoch {epoch}')\n",
    "    \n",
    "    if epoch >= 2 and epoch < 30:\n",
    "        os.remove(os.path.join(save_dir, f'epoch_{epoch-1}', save_name))\n",
    "        print(f'Removed model at epoch {epoch-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(-32, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cde1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(13, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4219cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(44, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(1, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(1, len(training_epoch_loss) + 1, 1)\n",
    "\n",
    "ax.scatter(x, training_epoch_loss, label='training loss')\n",
    "ax.scatter(x, val_epoch_loss, label='validation loss')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "\n",
    "print(training_epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d088c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee86b89",
   "metadata": {},
   "source": [
    "## FOURTH TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_Combined_CWRU_LBNL_ASU/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_CWRU_SunEdison/\"\n",
    "# root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_ASU/\"\n",
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Fresh_LBNL/\"\n",
    "\n",
    "# checkpoint_name = \"Fresh_Combined_CWRU_LBNL_ASU\"\n",
    "# checkpoint_name = \"Fresh_CWRU_SunEdison\"\n",
    "# checkpoint_name = \"Fresh_ASU\"\n",
    "checkpoint_name = \"Fresh_LBNL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd82d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = load_dataset(root)\n",
    "device, model = load_device_and_model(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val=1\n",
    "batch_size_train=1\n",
    "lr = 0.000001\n",
    "step_size=1\n",
    "gamma = 0.1\n",
    "num_epochs = 30\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "\n",
    "save_dir = get_save_dir(str(root), checkpoint_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "params_dict = {'batch_size_val' : batch_size_val,\n",
    "           'batch_size_train' : batch_size_train,\n",
    "           'lr' : lr,\n",
    "           'step_size' : step_size,\n",
    "           'gamma' : gamma,\n",
    "           'num_epochs' : num_epochs,\n",
    "           'criterion' : str(criterion)}\n",
    "\n",
    "with open(os.path.join(save_dir, 'params.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(params_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "lr_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "evaluate_metric=None\n",
    "running_record = {'train': {'loss': []}, 'val': {'loss': []}}\n",
    "\n",
    "save_name='model.pt'\n",
    "cache_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    \n",
    "    training_step_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        output_activated = 1 /(1 + torch.exp(-output))\n",
    "        target_onehot = torch.nn.functional.one_hot(target, num_classes = 5)\n",
    "        target_onehot = torch.moveaxis(target_onehot, 3, 1)\n",
    "        \n",
    "        training_loss = criterion(output_activated, target_onehot.float())\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        training_step_loss.append(training_loss.item())\n",
    "        \n",
    "    training_epoch_loss.append(np.array(training_step_loss).mean())\n",
    "        \n",
    "    val_step_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        output_activated = 1 /(1 + torch.exp(-output))\n",
    "        target_onehot = torch.nn.functional.one_hot(target, num_classes = 5)\n",
    "        target_onehot = torch.moveaxis(target_onehot, 3, 1)\n",
    "        val_loss = criterion(output_activated, target_onehot.float())\n",
    "        \n",
    "        val_step_loss.append(val_loss.item())\n",
    "        \n",
    "    val_epoch_loss.append(np.array(val_step_loss).mean())\n",
    "    \n",
    "    os.makedirs(os.path.join(save_dir, f'epoch_{epoch}'), exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f'epoch_{epoch}', save_name))\n",
    "    print(f'Saved model at epoch {epoch}')\n",
    "    \n",
    "    if epoch >= 2 and epoch < 30:\n",
    "        os.remove(os.path.join(save_dir, f'epoch_{epoch-1}', save_name))\n",
    "        print(f'Removed model at epoch {epoch-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ae378",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(-32, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80343ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(13, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(44, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20fc8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_and_show(1, retrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(1, len(training_epoch_loss) + 1, 1)\n",
    "\n",
    "ax.scatter(x, training_epoch_loss, label='training loss')\n",
    "ax.scatter(x, val_epoch_loss, label='validation loss')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "\n",
    "print(training_epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52642715",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_epoch_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
