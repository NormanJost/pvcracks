{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import wandb\n",
    "\n",
    "# pv_vision_dir = os.path.join(Path.home(), 'pv-vision')\n",
    "pv_vision_dir = os.path.join(\"/home/eccoope\", \"pv-vision\")\n",
    "# functions_dir = os.path.join(Path.home(), 'el_img_cracks_ec', 'scripts')\n",
    "functions_dir = os.path.join(\"/home/eccoope\", \"el_img_cracks_ec\", \"scripts\")\n",
    "\n",
    "sys.path.append(pv_vision_dir)\n",
    "sys.path.append(functions_dir)\n",
    "\n",
    "# ojas_functions_dir = os.path.join(Path.home(), 'pvcracks/retrain/')\n",
    "ojas_functions_dir = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks/retrain/\"\n",
    "sys.path.append(ojas_functions_dir)\n",
    "\n",
    "import functions\n",
    "from tutorials.unet_model import construct_unet\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- we split all the data into train/val/test\n",
    "\n",
    "- we split train and val into 5 folds (for example)\n",
    "\n",
    "- for each fold, we train a model. that's 5 models. \n",
    "\n",
    "- for each epoch as we train each fold, each fold-model-epoch has a set of metrics. we log those. we also keep a running average of metrics over time, per fold and log that.\n",
    "\n",
    "- we average the loss metrics across folds and get a value of how bad/good the model is. so after all 5 folds are run, we calculate the avg loss across the final epoch of all 5 folds. we log that and give it to wandb.\n",
    "\n",
    "- after training 5 folds, we also train a new model on the full train/val set. that's our 6th model. then we test it on our as-of-yet-unused test set. that's our true metric; we use that to compare model quality and maybe save the model if it's good. note this is done once per set of hyperparameters and never used to optimze anything.\n",
    "\n",
    "- wandb optimizes hyperparameters [using our avg loss across folds] and makes a new run. we repeat.\n",
    "\n",
    "- keep going till we want to stop the sweep.\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty/\"\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/pv-vision_model.pt\"\n",
    "\n",
    "checkpoint_name = \"wandb_\" + root.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"dark\", 1: \"busbar\", 2: \"crack\", 3: \"non-cell\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(pred, target, epsilon=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "    return dice\n",
    "\n",
    "def iou_score(pred, target, epsilon=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root):\n",
    "    transformers = functions.Compose(\n",
    "        [functions.ChanneledFixResize(256), functions.ToTensor(), functions.Normalize()]\n",
    "    )\n",
    "\n",
    "    full_dataset = functions.SolarDataset(\n",
    "        root, image_folder=\"img/all\", mask_folder=\"ann/all\", transforms=transformers\n",
    "    )\n",
    "\n",
    "    return full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_device_and_model(weight_path):\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"mps\")\n",
    "    unet = construct_unet(len(category_mapping))\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "\n",
    "    model = unet.module.to(device)\n",
    "\n",
    "    return device, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_dir(base_dir, checkpoint_name):\n",
    "    checkpoint_dir = base_dir + \"/checkpoints/\"\n",
    "    folders = [folder for folder in os.listdir(checkpoint_dir)]\n",
    "\n",
    "    max_number = 0\n",
    "    for folder in folders:\n",
    "        number = int(folder[-1])\n",
    "        if number > max_number:\n",
    "            max_number = number\n",
    "\n",
    "    new_folder_name = f\"{checkpoint_name}{max_number + 1}\"\n",
    "    new_folder_path = os.path.join(checkpoint_dir, new_folder_name)\n",
    "\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = load_dataset(root)\n",
    "\n",
    "trainval_set, test_set = train_test_split(full_dataset, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"model.pt\"\n",
    "save_dir = get_save_dir(str(root), checkpoint_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "original_config = {\n",
    "    \"batch_size_train\": 8,\n",
    "    \"lr\": 0.00092234,\n",
    "    \"gamma\": 0.11727,\n",
    "    \"num_epochs\": 1,\n",
    "    \n",
    "    # constants\n",
    "    \"batch_size_val\": 8,\n",
    "    \"criterion\": torch.nn.BCEWithLogitsLoss(),\n",
    "    \"k_folds\": 5,\n",
    "    # \"lr_scheduler_step_size\": 1,\n",
    "}\n",
    "\n",
    "config_serializable = original_config.copy()\n",
    "config_serializable[\"criterion\"] = str(config_serializable[\"criterion\"])\n",
    "\n",
    "with open(os.path.join(save_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_serializable, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"pvcracks\",\n",
    "    entity=\"ojas-sanghi-university-of-arizona\",\n",
    "    config=original_config,\n",
    ")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = config.k_folds\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to collect per-fold best metrics\n",
    "fold_val_losses = []\n",
    "fold_dice_scores = []\n",
    "fold_iou_scores = []\n",
    "\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainval_set)):\n",
    "    print(f\"\\n--- FOLD {fold+1}/{k_folds} ---\")\n",
    "\n",
    "    train_subsampler = torch.utils.data.Subset(trainval_set, train_ids)\n",
    "    train_loader = DataLoader(train_subsampler, batch_size=config.batch_size_train, shuffle=True)\n",
    "    val_subsampler = torch.utils.data.Subset(trainval_set, val_ids)\n",
    "    val_loader = DataLoader(val_subsampler, batch_size=config.batch_size_val, shuffle=False)\n",
    "\n",
    "    # Initialize a fresh model and optimizer\n",
    "    device, model = load_device_and_model(weight_path)\n",
    "    optimizer = Adam(model.parameters(), lr=config.lr)\n",
    "    run.watch(model, log_freq=100)\n",
    "    \n",
    "    best_fold_val_loss = float(\"inf\")\n",
    "    best_fold_dice = 0.0\n",
    "    best_fold_iou = 0.0\n",
    "    \n",
    "    # PER-EPOCH TRAINING\n",
    "    for epoch in tqdm(range(1, config.num_epochs + 1)):\n",
    "        training_step_loss = []\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            target = target.float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            training_loss = original_config[\"criterion\"](output, target)\n",
    "            training_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_step_loss.append(training_loss.item())\n",
    "\n",
    "        val_step_loss = []\n",
    "        dice_scores = []\n",
    "        iou_scores = []\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            target = target.float()\n",
    "            output = model(data)\n",
    "            \n",
    "            val_loss = original_config[\"criterion\"](output, target)\n",
    "            val_step_loss.append(val_loss.item())\n",
    "\n",
    "            # compute dice and iou\n",
    "            pred_probs = torch.sigmoid(output)\n",
    "            pred_binary = (pred_probs > 0.5).float()\n",
    "            for i in range(pred_binary.size(1)):\n",
    "                dice = dice_coefficient(pred_binary[:, i], target[:, i])\n",
    "                iou = iou_score(pred_binary[:, i], target[:, i])\n",
    "                dice_scores.append(dice.item())\n",
    "                iou_scores.append(iou.item())\n",
    "\n",
    "        epoch_train_loss = np.mean(training_step_loss)\n",
    "        epoch_val_loss = np.mean(val_step_loss)\n",
    "        epoch_avg_dice = np.mean(dice_scores)\n",
    "        epoch_avg_iou = np.mean(iou_scores)\n",
    "\n",
    "        # Log per-fold, per-epoch to W&B\n",
    "        run.log({\n",
    "            f\"fold{fold+1}/train_loss\": epoch_train_loss,\n",
    "            f\"fold{fold+1}/val_loss\":   epoch_val_loss,\n",
    "            f\"fold{fold+1}/dice\":       epoch_avg_dice,\n",
    "            f\"fold{fold+1}/iou\":        epoch_avg_iou,\n",
    "        }, step=epoch)\n",
    "\n",
    "        # Keep best for this fold\n",
    "        if epoch_val_loss < best_fold_val_loss:\n",
    "            best_fold_val_loss = epoch_val_loss\n",
    "            best_fold_dice = epoch_avg_dice\n",
    "            best_fold_iou = epoch_avg_iou\n",
    "    \n",
    "    print(f\"Fold {fold+1} best val_loss: {best_fold_val_loss:.4f}, dice: {best_fold_dice:.4f}, iou: {best_fold_iou:.4f}\")\n",
    "    \n",
    "    fold_val_losses.append(best_fold_val_loss)\n",
    "    fold_dice_scores.append(best_fold_dice)\n",
    "    fold_iou_scores.append(best_fold_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== AGGREGATE RESULTS ACROSS FOLDS ==========\n",
    "\n",
    "avg_val_loss = np.mean(fold_val_losses)\n",
    "avg_dice     = np.mean(fold_dice_scores)\n",
    "avg_iou      = np.mean(fold_iou_scores)\n",
    "\n",
    "# Log the averages to W&B summary for sweep optimization\n",
    "wandb.run.summary[\"avg_val_loss\"] = avg_val_loss\n",
    "wandb.log({\n",
    "    \"avg_val_loss\": avg_val_loss,\n",
    "    \"avg_dice\":     avg_dice,\n",
    "    \"avg_iou\":      avg_iou,\n",
    "})\n",
    "\n",
    "print(f\"Average val_loss: {avg_val_loss:.4f}, dice: {avg_dice:.4f}, iou: {avg_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_inference_and_show(idx, threshold=0.5):\n",
    "    # Get the preprocessed image and multi-hot ground truth mask\n",
    "    img, mask = train_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # Get the raw image for display (assuming __getraw__ returns a PIL image)\n",
    "    raw_img, _ = train_loader.dataset.__getraw__(idx)\n",
    "\n",
    "    # --- Run inference ---\n",
    "    # Get raw logits from the model, then apply Sigmoid and threshold\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()  # shape: [1, 4, H, W]\n",
    "    probs = torch.sigmoid(logits)  # shape: [1, 4, H, W]\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()  # shape: [4, H, W]\n",
    "\n",
    "    # Ground truth is assumed to be already a 4-channel multi-hot mask.\n",
    "    gt_mask = mask.cpu().numpy()  # shape: [4, H, W]\n",
    "\n",
    "    # --- Visualization ---\n",
    "    # Create a grid with 3 rows and 4 columns:\n",
    "    #   Row 0: Raw image (displayed only once in the first column)\n",
    "    #   Row 1: Ground truth masks for each class\n",
    "    #   Row 2: Predicted masks for each class\n",
    "    n_classes = len(category_mapping)\n",
    "    class_names = [f\"({k}) {v}\" for k, v in category_mapping.items()]\n",
    "\n",
    "    fig, axs = plt.subplots(3, n_classes, figsize=(4 * n_classes, 12))\n",
    "\n",
    "    # Row 0: Display raw image in first subplot; hide other subplots in this row.\n",
    "    axs[0, 0].imshow(raw_img.convert(\"L\"), cmap=\"viridis\")\n",
    "    axs[0, 0].set_title(\"Raw Image\")\n",
    "    axs[0, 0].axis(\"off\")\n",
    "    for j in range(1, n_classes):\n",
    "        axs[0, j].axis(\"off\")\n",
    "\n",
    "    # Row 1: Ground truth for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[1, j].imshow(gt_mask[j], cmap=\"viridis\")\n",
    "        axs[1, j].set_title(f\"GT: {class_names[j]}\")\n",
    "        axs[1, j].axis(\"off\")\n",
    "\n",
    "    # Row 2: Predictions for each class (each channel)\n",
    "    for j in range(n_classes):\n",
    "        axs[2, j].imshow(pred_mask[j], cmap=\"viridis\")\n",
    "        axs[2, j].set_title(f\"Pred: {class_names[j]}\")\n",
    "        axs[2, j].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(\"Retrained Model Prediction\", fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inference_and_show(13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
