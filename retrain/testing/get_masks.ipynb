{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from imutils.paths import list_images, list_files\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eccoope/pv-vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eccoope/dmenv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd /home/eccoope/pv-vision/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pv_vision.nn import ModelHandler\n",
    "from tutorials.unet_model import construct_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # will put this method into util in the future\n",
    "# class SolarDataset(VisionDataset):\n",
    "#     \"\"\"A dataset directly read images and masks from folder.    \n",
    "#     \"\"\"\n",
    "#     def __init__(self, \n",
    "#                  root, \n",
    "#                  image_folder, \n",
    "#                  mask_folder,\n",
    "#                  transforms,\n",
    "#                  mode = \"train\",\n",
    "#                  random_seed=42):\n",
    "#         super().__init__(root, transforms)\n",
    "#         self.image_path = Path(self.root) / image_folder\n",
    "#         self.mask_path = Path(self.root) / mask_folder\n",
    "\n",
    "#         if not os.path.exists(self.image_path):\n",
    "#             raise OSError(f\"{self.image_path} not found.\")\n",
    "\n",
    "#         if not os.path.exists(self.mask_path):\n",
    "#             raise OSError(f\"{self.mask_path} not found.\")\n",
    "\n",
    "#         self.image_list = sorted(list(list_images(self.image_path)))\n",
    "#         self.mask_list = sorted(list(list_images(self.mask_path)))\n",
    "\n",
    "#         self.image_list = np.array(self.image_list)\n",
    "#         self.mask_list = np.array(self.mask_list)\n",
    "\n",
    "#         # np.random.seed(random_seed)\n",
    "#         # index = np.arange(len(self.image_list))\n",
    "#         # np.random.shuffle(index)\n",
    "#         # self.image_list = self.image_list[index]\n",
    "#         # self.mask_list = self.mask_list[index]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_list)\n",
    "\n",
    "#     def __getname__(self, index):\n",
    "#         image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
    "#         mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
    "\n",
    "#         if image_name == mask_name:\n",
    "#             return image_name\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "#     def __getraw__(self, index):\n",
    "#         if not self.__getname__(index):\n",
    "#             raise ValueError(\"{}: Image doesn't match with mask\".format(os.path.split(self.image_list[index])[-1]))\n",
    "#         image = Image.open(self.image_list[index])\n",
    "#         mask = Image.open(self.mask_list[index]).convert('L')\n",
    "#         mask = np.array(mask)\n",
    "#         mask = Image.fromarray(mask)\n",
    "\n",
    "#         return image, mask\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image, mask = self.__getraw__(index)\n",
    "#         image, mask = self.transforms(image, mask)\n",
    "\n",
    "#         return image, mask\n",
    "\n",
    "# # will put into utils in the future\n",
    "# class Compose:\n",
    "#     def __init__(self, transforms):\n",
    "#         \"\"\"\n",
    "#         transforms: a list of transform\n",
    "#         \"\"\"\n",
    "#         self.transforms = transforms\n",
    "    \n",
    "#     def __call__(self, image, target):\n",
    "#         \"\"\"\n",
    "#         image: input image\n",
    "#         target: input mask\n",
    "#         \"\"\"\n",
    "#         for t in self.transforms:\n",
    "#             image, target = t(image, target)\n",
    "#         return image, target\n",
    "\n",
    "# class FixResize:\n",
    "#     # UNet requires input size to be multiple of 16\n",
    "#     def __init__(self, size):\n",
    "#         self.size = size\n",
    "\n",
    "#     def __call__(self, image, target):\n",
    "#         image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "#         target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "#         return image, target\n",
    "\n",
    "# class ToTensor:\n",
    "#     \"\"\"Transform the image to tensor. Scale the image to [0,1] float32.\n",
    "#     Transform the mask to tensor.\n",
    "#     \"\"\"\n",
    "#     def __call__(self, image, target):\n",
    "#         image = transforms.ToTensor()(image)\n",
    "#         target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "#         return image, target\n",
    "\n",
    "# class PILToTensor:\n",
    "#     \"\"\"Transform the image to tensor. Keep raw type.\"\"\"\n",
    "#     def __call__(self, image, target):\n",
    "#         image = F.pil_to_tensor(image)\n",
    "#         target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "#         return image, target\n",
    "\n",
    "# class Normalize:\n",
    "#     def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "#         self.mean = mean\n",
    "#         self.std = std\n",
    "    \n",
    "#     def __call__(self, image, target):\n",
    "#         image = F.normalize(image, mean=self.mean, std=self.std)\n",
    "#         return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images and lables are only for tutorial demosntration.\n",
    "# The complete data set we used for model development can be found here:\n",
    "# https://datahub.duramat.org/dataset/00b29daf-239c-47b6-bd96-bfb0875179a8/resource/5e9d5503-cb2f-42b7-be5a-282514c60f39/download/train_val_upsample_aug.zip\n",
    "\n",
    "root = Path('/home/eccoope/pv-vision/examples/crack_segmentation/img_label_for_training')\n",
    "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
    "trainset = functions.SolarDataset(root, image_folder=\"train/img\", \n",
    "        mask_folder=\"train/ann\", transforms=transformers)\n",
    "\n",
    "valset = functions.SolarDataset(root, image_folder=\"val/img\", \n",
    "        mask_folder=\"val/ann\", transforms=transformers)\n",
    "\n",
    "testset = functions.SolarDataset(root, image_folder=\"testset/img\", \n",
    "        mask_folder=\"testset/ann\", transforms=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.colormaps['viridis'].resampled(5)  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(5)]\n",
    "\n",
    "for i in range(800):\n",
    "\n",
    "    img, mask = trainset. __getitem__(i)\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    raw_img, _ = trainset. __getraw__(i)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 7), layout='compressed')\n",
    "\n",
    "    ax[0].imshow(raw_img, cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    im = ax[1].imshow(mask_cpu, cmap='viridis')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    handles, labels = ax[1].get_legend_handles_labels()\n",
    "\n",
    "    for c, classlabel in zip(cmaplist, ['(0) empty', '(1) dark', '(2) cross', '(3) crack', '(4) busbar']):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec='k')\n",
    "        handles.append(patch)\n",
    "    ax[1].legend(handles=handles, fontsize='x-small')\n",
    "\n",
    "    plt.savefig(os.path.join(Path.home(), 'el_img_cracks_ec', 'pv_vision_targets', trainset. __getname__(i) + '.jpg'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
