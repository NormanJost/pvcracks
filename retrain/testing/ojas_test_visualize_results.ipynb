{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import skimage\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import functions\n",
    "from tutorials.unet_model import construct_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root):\n",
    "    transformers = functions.Compose([functions.FixResize(256), functions.ToTensor(), functions.Normalize()])\n",
    "\n",
    "    val_dataset = functions.SolarDataset(root, image_folder=\"img/val\", \n",
    "            mask_folder=\"ann/val\", transforms=transformers)\n",
    "    \n",
    "    return val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_device_and_model(weight_path):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    unet = construct_unet(5)\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "    \n",
    "    checkpoint = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint.items():\n",
    "        name = \"module.\" + k\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    unet.load_state_dict(new_state_dict)\n",
    "\n",
    "    model = unet.module.to(device)\n",
    "    \n",
    "    return device, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(mask, raw_img, test_res, layers_to_render=None, retrained=False):\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    cmap = mpl.colormaps['viridis'].resampled(5)  # define the colormap\n",
    "    cmaplist = [cmap(i) for i in range(5)]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12,12))\n",
    "\n",
    "    im = ax[0].imshow(raw_img.convert('L'), cmap='gray', interpolation='None')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    clim = (0, 4)\n",
    "    im = ax[1].imshow(mask_cpu, cmap='viridis', clim=clim)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "    if layers_to_render is not None:\n",
    "        test_res = np.where(np.isin(test_res, layers_to_render), test_res, 0)\n",
    "\n",
    "    ax[2].imshow(test_res, cmap='viridis', clim=clim, interpolation='None')\n",
    "    handles, labels = ax[2].get_legend_handles_labels()\n",
    "\n",
    "    for c, classlabel in zip(cmaplist, [f'({k}) {v}' for k, v in category_mapping.items()]):\n",
    "            patch = mpatches.Patch(color=c, label=classlabel, ec='k')\n",
    "            handles.append(patch)\n",
    "    ax[2].legend(handles=handles, fontsize='x-small')\n",
    "    ax[2].axis('off')\n",
    "    if retrained:\n",
    "        ax[2].set_title(\"Retrained Model Prediction\")\n",
    "    else:\n",
    "        ax[2].set_title(\"Model Prediction\")\n",
    "\n",
    "def inference_and_show(idx, root, weight_path, load_val = False, batch_size=1, retrained=False, layers_to_render=None):\n",
    "    val_dataset = load_dataset(root, load_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    device, model = load_device_and_model(weight_path)\n",
    "    \n",
    "    img, mask = val_loader.dataset.__getitem__(idx)\n",
    "    img = img.to(device)\n",
    "    raw_img, _ = val_loader.dataset.__getraw__(idx)\n",
    "    test_res = model(img.unsqueeze(0)).detach().cpu().numpy().squeeze()\n",
    "    test_res = np.argmax(test_res, axis=0)\n",
    "    \n",
    "    show(mask, raw_img, test_res, retrained=retrained, layers_to_render=layers_to_render)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference w/ Magic Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My model w/ my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "\n",
    "root = Path('/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/')\n",
    "weight_path = '/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/checkpoints/retrain_corners_checkpoint3/epoch_30/model.pt'\n",
    "\n",
    "inference_and_show(1, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emma model with my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"busbar\", 2: \"dark\", 3: \"cross\", 4: \"dark\"}\n",
    "\n",
    "root = Path('/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/')\n",
    "weight_path = '/home/osanghi/pvcracks/retrained_pv-vision_model.pt'\n",
    "\n",
    "inference_and_show(1, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My model with no corners data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"dark\", 2: \"busbar\", 3: \"crack\", 4: \"corner\"}\n",
    "\n",
    "root = Path('/projects/wg-psel-ml/EL_images/osanghi/Norman_ELImages_NoCorners/')\n",
    "weight_path = '/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/checkpoints/retrain_corners_checkpoint3/epoch_30/model.pt'\n",
    "\n",
    "inference_and_show(1, root, weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emma model w/ emma data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"empty\", 1: \"busbar\", 2: \"dark\", 3: \"cross\", 4: \"dark\"}\n",
    "\n",
    "root = Path('/projects/wg-psel-ml/EL_images/eccoope')\n",
    "weight_path = '/home/osanghi/pvcracks/retrained_pv-vision_model.pt'\n",
    "\n",
    "inference_and_show(1, root, weight_path, load_val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OG weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = Path('/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE')\n",
    "# weight_path = '/projects/wg-psel-ml/EL_images/osanghi/CornersIHDEANE/checkpoints/retrain_corners_checkpoint3/epoch_30/model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_and_show(1, root, weight_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
