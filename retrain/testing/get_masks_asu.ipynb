{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import logging\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "import copy\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from imutils.paths import list_images, list_files\n",
    "import os\n",
    "\n",
    "# cd ~/pv-vision/\n",
    "\n",
    "pv_vision_dir = os.path.join(Path.home(), 'pv-vision')\n",
    "functions_dir = os.path.join(Path.home(), 'el_img_cracks_ec', 'my_scripts')\n",
    "\n",
    "sys.path.append(pv_vision_dir)\n",
    "sys.path.append(functions_dir)\n",
    "\n",
    "from pv_vision.nn import ModelHandler\n",
    "from tutorials.unet_model import construct_unet\n",
    "import functions\n",
    "\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will put this method into util in the future\n",
    "class SolarDataset(VisionDataset):\n",
    "    \"\"\"A dataset directly read images and masks from folder.    \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 image_folder, \n",
    "                 mask_folder,\n",
    "                 transforms,\n",
    "                 mode = \"train\",\n",
    "                 random_seed=42):\n",
    "        super().__init__(root, transforms)\n",
    "        self.image_path = Path(self.root) / image_folder\n",
    "        self.mask_path = Path(self.root) / mask_folder\n",
    "\n",
    "        if not os.path.exists(self.image_path):\n",
    "            raise OSError(f\"{self.image_path} not found.\")\n",
    "\n",
    "        if not os.path.exists(self.mask_path):\n",
    "            raise OSError(f\"{self.mask_path} not found.\")\n",
    "\n",
    "        self.image_list = sorted(list(list_images(self.image_path)))\n",
    "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
    "\n",
    "        self.image_list = np.array(self.image_list)\n",
    "        self.mask_list = np.array(self.mask_list)\n",
    "\n",
    "        # np.random.seed(random_seed)\n",
    "        # index = np.arange(len(self.image_list))\n",
    "        # np.random.shuffle(index)\n",
    "        # self.image_list = self.image_list[index]\n",
    "        # self.mask_list = self.mask_list[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getname__(self, index):\n",
    "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
    "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
    "\n",
    "        if image_name == mask_name:\n",
    "            return image_name\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __getraw__(self, index):\n",
    "        if not self.__getname__(index):\n",
    "            raise ValueError(\"{}: Image doesn't match with mask\".format(os.path.split(self.image_list[index])[-1]))\n",
    "        image = Image.open(self.image_list[index])\n",
    "        mask = Image.open(self.mask_list[index]).convert('L')\n",
    "        mask = np.array(mask)\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, mask = self.__getraw__(index)\n",
    "        image, mask = self.transforms(image, mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# will put into utils in the future\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        \"\"\"\n",
    "        transforms: a list of transform\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        \"\"\"\n",
    "        image: input image\n",
    "        target: input mask\n",
    "        \"\"\"\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "class FixResize:\n",
    "    # UNet requires input size to be multiple of 16\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        return image, target\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\"Transform the image to tensor. Scale the image to [0,1] float32.\n",
    "    Transform the mask to tensor.\n",
    "    \"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = transforms.ToTensor()(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "class PILToTensor:\n",
    "    \"\"\"Transform the image to tensor. Keep raw type.\"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = F.pil_to_tensor(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "class Normalize:\n",
    "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/projects/wg-psel-ml/EL_images/eccoope')\n",
    "transformers = functions.Compose([functions.FixResize(256), functions.ToTensor(), functions.Normalize()])\n",
    "\n",
    "trainset = functions.SolarDataset(root, image_folder=\"img/train\", \n",
    "        mask_folder=\"ann/train\", transforms=transformers)\n",
    "\n",
    "valset = functions.SolarDataset(root, image_folder=\"img/val\", \n",
    "        mask_folder=\"ann/val\", transforms=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.colormaps['viridis'].resampled(5)  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(5)]\n",
    "\n",
    "for i in range(261):\n",
    "\n",
    "# i = 8\n",
    "\n",
    "    img, mask = trainset. __getitem__(i)\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    raw_img, _ = trainset. __getraw__(i)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 7), layout='compressed')\n",
    "\n",
    "    ax[0].imshow(raw_img, cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    im = ax[1].imshow(mask_cpu, cmap='viridis')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    handles, labels = ax[1].get_legend_handles_labels()\n",
    "\n",
    "    for c, classlabel in zip(cmaplist, ['(0) empty', '(1) dark', '(2) cross', '(3) crack', '(4) busbar']):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec='k')\n",
    "        handles.append(patch)\n",
    "    ax[1].legend(handles=handles, fontsize='x-small')\n",
    "\n",
    "    plt.savefig(os.path.join(Path.home(), 'el_img_cracks_ec', 'asu_targets', trainset. __getname__(i) + '.jpg'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.colormaps['viridis'].resampled(5)  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(5)]\n",
    "\n",
    "for i in range(87):\n",
    "\n",
    "# i = 8\n",
    "\n",
    "    img, mask = valset. __getitem__(i)\n",
    "    mask_cpu = mask.cpu().numpy()\n",
    "\n",
    "    raw_img, _ = valset. __getraw__(i)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 7), layout='compressed')\n",
    "\n",
    "    ax[0].imshow(raw_img, cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    im = ax[1].imshow(mask_cpu, cmap='viridis')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    handles, labels = ax[1].get_legend_handles_labels()\n",
    "\n",
    "    for c, classlabel in zip(cmaplist, ['(0) empty', '(1) dark', '(2) cross', '(3) crack', '(4) busbar']):\n",
    "        patch = mpatches.Patch(color=c, label=classlabel, ec='k')\n",
    "        handles.append(patch)\n",
    "    ax[1].legend(handles=handles, fontsize='x-small')\n",
    "\n",
    "    plt.savefig(os.path.join(Path.home(), 'el_img_cracks_ec', 'asu_targets', trainset. __getname__(i) + '.jpg'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "264/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmenv",
   "language": "python",
   "name": "dmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
