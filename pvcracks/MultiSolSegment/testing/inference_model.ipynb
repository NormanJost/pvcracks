{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e818d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pvimage import features\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "\n",
    "from pvcracks.utils import train_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00977467",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: \"dark\", 1: \"busbar\", 2: \"crack\", 3: \"non-cell\"}\n",
    "root = Path(\n",
    "    \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty/\"\n",
    ")\n",
    "img_root = root / \"img\" / \"all\"\n",
    "weight_path = \"/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty/checkpoints/Channeled_Combined_CWRU_LBNL_ASU_No_Empty10/epoch_19/model.pt\"\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = train_functions.load_dataset(root)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "device, model = train_functions.load_device_and_model(\n",
    "    category_mapping, existing_weight_path=weight_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b029503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "threshold = 0.5\n",
    "\n",
    "# viz_functions.channeled_inference_and_show(\n",
    "#         val_loader, device, model, category_mapping, idx\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d6c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "img, mask = val_loader.dataset.__getitem__(idx)\n",
    "img = img.to(device)\n",
    "raw_img, _ = val_loader.dataset.__getraw__(idx)\n",
    "\n",
    "# Mask\n",
    "gt_mask = mask.cpu().numpy()\n",
    "\n",
    "# Inference\n",
    "logits = model(img.unsqueeze(0)).detach().cpu()\n",
    "probs = torch.sigmoid(logits)\n",
    "pred_mask = (probs > threshold).float().squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d226d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = val_loader.dataset.__get_img_path__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9ddb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ojas/Desktop/saj/SANDIA/pvcracks_data/Channeled_Combined_CWRU_LBNL_ASU_No_Empty/img/val/mxy_sa19965_sub_EL_9-c02.tiff\n"
     ]
    }
   ],
   "source": [
    "print(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6b803",
   "metadata": {},
   "source": [
    "----\n",
    "VAE reconstruction attempt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "\n",
    "array_new = []\n",
    "for i in range(585):\n",
    "    img_path = val_loader.dataset.__get_img_path__(idx)\n",
    "    dat = iio.imread(img_path)\n",
    "    # dat = Image.open(img_path)\n",
    "    datmean = dat.mean()\n",
    "    dat = (dat > datmean).astype(np.float32)\n",
    "    array_new.append(dat)\n",
    "    paths.append(img_path)\n",
    "\n",
    "array_new = np.stack(array_new)\n",
    "print(\"Size of new array with cracked images %s\" % str(array_new.shape))\n",
    "\n",
    "testimg = array_new[-99:, :, :, 1:2]\n",
    "testpaths = paths[-99:]\n",
    "dfinfo = pd.DataFrame()\n",
    "dfinfo[\"impath\"] = testpaths\n",
    "\n",
    "dffeaturesreal = features.feature_extraction_crack_mask(testimg, dfinfo)\n",
    "\n",
    "dffeaturesreal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eff842",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensors = []\n",
    "masks = []\n",
    "\n",
    "mask_index = -99\n",
    "# GO BETWEEEN PATH / INDEX /?\n",
    "\n",
    "preds = []\n",
    "\n",
    "for p in testpaths:\n",
    "    img, _ = val_loader.dataset.__getitem__(mask_index)\n",
    "    img = img.to(device)\n",
    "    # _, mask = val_loader.dataset.__getraw__(idx)\n",
    "    # get associated mask path (sometihng -99 onwards ??)\n",
    "    # mask = np.load(mask)\n",
    "\n",
    "    # transformers = img_functions.Compose(\n",
    "    #     [\n",
    "    #         img_functions.ChanneledFixResize(256),\n",
    "    #         img_functions.ToTensor(),\n",
    "    #         img_functions.Normalize(),\n",
    "    #     ]\n",
    "    # )\n",
    "    # img_tensor = transformers(image, ).to(device)\n",
    "    # image_tensors.append(img.unsqueeze(0))\n",
    "    # masks.append(mask)\n",
    "\n",
    "    logits = model(img.unsqueeze(0)).detach().cpu()\n",
    "    probs = torch.sigmoid(logits)\n",
    "    pred_mask = (probs > threshold).float().squeeze(0).numpy()\n",
    "    preds.append(pred_mask)\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "print(preds)\n",
    "\n",
    "# testtensors = torch.stack(image_tensors)\n",
    "# logits = model(testtensors).detach().cpu()\n",
    "# probs = torch.sigmoid(logits)\n",
    "# pred_mask = (probs > threshold).float().squeeze(0).numpy()\n",
    "testimg_reshaped = np.reshape(preds, (99, 400, 400, 1))\n",
    "\n",
    "# testpreds = torch.stack(preds)\n",
    "\n",
    "dffeaturesout = features.feature_extraction_crack_mask(testimg_reshaped, dfinfo)\n",
    "\n",
    "dffeaturesout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f8a2c",
   "metadata": {},
   "source": [
    "Some problem here -- the VAE example is comparing an image and a (reconstructed) image.  \n",
    "Here I would want to compare masks and masks -- both 3d arrays (4-channeled 2d arrays).  \n",
    "But I'm not sure if pvimage actually enables that nor how it's supposed to work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d56c2",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76cf7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_activation_percentages(mask, category_mapping):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of pixels activated for each channel in a multi-hot mask.\n",
    "\n",
    "    Args:\n",
    "        mask: 3D array-like of shape (n_channels, height, width) containing multi-hot activations.\n",
    "        category_mapping (dict): Mapping from channel index to class name. The iteration order\n",
    "            defines the channel order in the mask tensor.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping from class name to percentage (0-100) of activated pixels in that channel.\n",
    "    \"\"\"\n",
    "    mask_np = np.asarray(mask)\n",
    "\n",
    "    if mask_np.ndim != 3:\n",
    "        raise ValueError(\n",
    "            f\"Expected a 3D mask of shape (channels, height, width); got {mask_np.shape}.\"\n",
    "        )\n",
    "\n",
    "    n_channels, height, width = mask_np.shape\n",
    "    total_pixels = height * width\n",
    "\n",
    "    if total_pixels == 0:\n",
    "        raise ValueError(\"Mask must contain at least one pixel.\")\n",
    "\n",
    "    percentages = {}\n",
    "    for channel_idx, class_name in category_mapping.items():\n",
    "        if channel_idx >= n_channels:\n",
    "            raise ValueError(\n",
    "                f\"Channel index {channel_idx} for class '{class_name}' is out of bounds \"\n",
    "                f\"for mask with {n_channels} channel(s).\"\n",
    "            )\n",
    "        channel_activation = mask_np[channel_idx].sum()\n",
    "        percentages[class_name] = float(channel_activation) / float(total_pixels) * 100.0\n",
    "\n",
    "    return percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58d87f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_channel_activation_percentages(percentages):\n",
    "    print(\"Predicted channel activation (% of image):\")\n",
    "    sum = 0\n",
    "    for _, class_name in category_mapping.items():\n",
    "        print(f\"\\t{class_name}: {percentages[class_name]:.2f}%\")\n",
    "        sum += percentages[class_name]\n",
    "    print(\"\\tRemaining (solar cell): %.2f%%\\n\" % (100 - sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69aadd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted channel activation (% of image):\n",
      "\tdark: 0.00%\n",
      "\tbusbar: 11.46%\n",
      "\tcrack: 12.51%\n",
      "\tnon-cell: 1.48%\n",
      "\tRemaining (solar cell): 74.55%\n",
      "\n",
      "Predicted channel activation (% of image):\n",
      "\tdark: 0.00%\n",
      "\tbusbar: 10.21%\n",
      "\tcrack: 10.35%\n",
      "\tnon-cell: 1.95%\n",
      "\tRemaining (solar cell): 77.48%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gt_percentages = channel_activation_percentages(gt_mask, category_mapping)\n",
    "pred_percentages = channel_activation_percentages(pred_mask, category_mapping)\n",
    "\n",
    "print_channel_activation_percentages(gt_percentages)\n",
    "print_channel_activation_percentages(pred_percentages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvcracks (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
